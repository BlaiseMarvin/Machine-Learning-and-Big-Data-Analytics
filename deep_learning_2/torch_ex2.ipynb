{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44eecd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62156ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([4, 5, 6], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = np.array([4,5,6],dtype=np.int32)\n",
    "\n",
    "t_a = torch.tensor(a)\n",
    "t_b = torch.from_numpy(b)\n",
    "\n",
    "print(t_a)\n",
    "print(t_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f17dd5",
   "metadata": {},
   "source": [
    "Results in tensors t_a and t_b with their properties (shape and data type) adopted from their source. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a52765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ones = torch.ones(2,3)\n",
    "t_ones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0094cee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(t_ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585d6385",
   "metadata": {},
   "source": [
    "Finally, creating a tensor from random values can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06822b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3623, 0.3692, 0.8871],\n",
      "        [0.9506, 0.0168, 0.1237]])\n"
     ]
    }
   ],
   "source": [
    "rand_tensor = torch.rand(2,3)\n",
    "print(rand_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7317ba30",
   "metadata": {},
   "source": [
    "Manipulating the data type and shape of a tensor:\n",
    "- Manipulating tensors via several functions that cast, reshape, transpose, squeeze (remove dimensions).\n",
    "- The torch.to() function can be used to change the data type of a tensor to a desired type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b257e731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b997726a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "t_a_new = t_a.to(torch.int64)\n",
    "print(t_a_new.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e52fba7",
   "metadata": {},
   "source": [
    "Manipulating the shape of a tensor:\n",
    "- PyTorch provides useful functions (or operations) to achieve this\n",
    "- such as torch.transpose(), torch.reshape(), and torch.squeeze()\n",
    "- ex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c71e7192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5])  -->  torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand(3,5)\n",
    "t_tr = torch.transpose(t,0,1)\n",
    "print(t.shape,' --> ',t_tr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0aaf5c",
   "metadata": {},
   "source": [
    "Reshaping a tensor e.g. (1D to 2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f5c2d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "t = torch.zeros(30)\n",
    "t_reshape = t.reshape(5,6)\n",
    "print(t_reshape.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5687d7",
   "metadata": {},
   "source": [
    "Removing the unncecessary dimensions (dimensions that have size 1, which are not needed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b20a705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 1, 4, 1])  -->  torch.Size([1, 2, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "t = torch.zeros(1,2,1,4,1)\n",
    "t_sqz = torch.squeeze(t, 2)\n",
    "print(t.shape,' --> ',t_sqz.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c21d15",
   "metadata": {},
   "source": [
    "**Applying mathematical operations to tensors:**\n",
    "- Applying math ops in particular linear algebra is necessary for building most ml models. We now cover some widely used linear algebra operations such as element-wise product, matrix mul, computing the norm of a tensor.\n",
    "- First, lets instantiate two random tensors, one with uniform distribution in the range (-1,1) and the other with a standard normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39ef6938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x17ad9b7ea50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9520921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = 2*torch.rand(5,2)-1\n",
    "t2 = torch.normal(mean=0, std=1, size=(5,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c86fd7",
   "metadata": {},
   "source": [
    "Now, to compute the element-wise product of t1 and t2, we use the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c965f65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4426, -0.3114],\n",
      "        [ 0.0660, -0.5970],\n",
      "        [ 1.1249,  0.0150],\n",
      "        [ 0.1569,  0.7107],\n",
      "        [-0.0451, -0.0352]])\n"
     ]
    }
   ],
   "source": [
    "t3 = torch.multiply(t1,t2)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f96023",
   "metadata": {},
   "source": [
    "to compute the mean, sum, and standard deviation along a certain axis (or axes), we use torch.mean(), torch.sum(), and torch.std(). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6dc83b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5153, -0.4414],\n",
       "        [-0.1939,  0.4694],\n",
       "        [-0.9414,  0.5997],\n",
       "        [-0.2057,  0.5087],\n",
       "        [ 0.1390, -0.1224]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89823026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1373,  0.2028])\n"
     ]
    }
   ],
   "source": [
    "t4 = torch.mean(t1, axis=0)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1c0960",
   "metadata": {},
   "source": [
    "matrix-matrix product between t1 and t2 -> computed using torch.matmul:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a6a8fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 2]), torch.Size([5, 2]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape, t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53050f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1312,  0.3860, -0.6267, -1.0096, -0.2943],\n",
      "        [ 0.1647, -0.5310,  0.2434,  0.8035,  0.1980],\n",
      "        [-0.3855, -0.4422,  1.1399,  1.5558,  0.4781],\n",
      "        [ 0.1822, -0.5771,  0.2585,  0.8676,  0.2132],\n",
      "        [ 0.0330,  0.1084, -0.1692, -0.2771, -0.0804]])\n"
     ]
    }
   ],
   "source": [
    "t5 = torch.matmul(t1, torch.transpose(t2,0,1))\n",
    "print(t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48ebd1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7453,  0.3392],\n",
      "        [-1.6038, -0.2180]])\n"
     ]
    }
   ],
   "source": [
    "t6 = torch.matmul(torch.transpose(t1,0,1),t2)\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d0f4a4",
   "metadata": {},
   "source": [
    "finally, the torch.linalg.norm fxn is for computing the Lp norm of a tensor. for example, we can calculate the L2 norm of t1 as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd6bf6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5153, -0.4414],\n",
       "        [-0.1939,  0.4694],\n",
       "        [-0.9414,  0.5997],\n",
       "        [-0.2057,  0.5087],\n",
       "        [ 0.1390, -0.1224]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40c47e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_t1 = torch.linalg.norm(t1, ord=2, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bc0e51",
   "metadata": {},
   "source": [
    "**Math operations to a tensor:**\n",
    "- We cover some widely used linear algebra operations, such as element-wise product, matrix multiplication, and computing the norm of a tensor:\n",
    "- First, lets instantiate two random tensors, one with uniform distribution with the range (-1,1) and the other with a standard normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e97b819f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x17ad9b7ea50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting the random seed:\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b806a4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = 2*torch.rand(5,2)-1\n",
    "t2 = torch.normal(mean=0,std=1,size=(5,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0fc2e7",
   "metadata": {},
   "source": [
    "Now, to compute the element-wise product of t1 and t2, we can use the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "376044be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4426, -0.3114],\n",
      "        [ 0.0660, -0.5970],\n",
      "        [ 1.1249,  0.0150],\n",
      "        [ 0.1569,  0.7107],\n",
      "        [-0.0451, -0.0352]])\n"
     ]
    }
   ],
   "source": [
    "t3 = torch.multiply(t1,t2)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc4c1fe",
   "metadata": {},
   "source": [
    "to compute the mean, sum, and standard deviation along a certain axis (or axes), we can use torch.mean(), torch.sum(), and torch.std(). For example, the mean of each column in t1 can be computed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c477e2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1373,  0.2028])\n"
     ]
    }
   ],
   "source": [
    "t4 = torch.mean(t1, axis=0)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9dd0be",
   "metadata": {},
   "source": [
    "The matrix-matrix product is computed using the matmul function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "961d6dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7453,  0.3392],\n",
      "        [-1.6038, -0.2180]])\n"
     ]
    }
   ],
   "source": [
    "t6 = torch.matmul(torch.transpose(t1,0,1),t2)\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c378a6c",
   "metadata": {},
   "source": [
    "Finally, the torch.linalg.norm function is useful for computing the Lp norm of a tensor. For example, we can calculate the L2 norm as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27854ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5153, -0.4414],\n",
       "        [-0.1939,  0.4694],\n",
       "        [-0.9414,  0.5997],\n",
       "        [-0.2057,  0.5087],\n",
       "        [ 0.1390, -0.1224]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06ee1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_t1 = torch.linalg.norm(t1, ord=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac1de4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6785, 0.5078, 1.1162, 0.5488, 0.1853])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82efeec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6785042741206573"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((0.5153**2)+(-0.4414)**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccda73ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67846215, 0.5078282 , 1.1162277 , 0.5487652 , 0.18525197],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum(np.square(t1.numpy()),axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e2a250",
   "metadata": {},
   "source": [
    "Split, Stack, and Concatenate Tensors:\n",
    "- We now cover pytorch operations for splitting a tensor into multiple tensors, or the recerse: stacking and concatenating multiple tensors into a single one\n",
    "- Assume we have a single tensor, and we want to split it into two or more tensors. Pytorch provides the convenient fxn: torch.chunk(), which divides an input tensor into a list of equally sized tensors. We can determine the desired number of splits as an integer using the chunks argument to split a tensor along the desired dimension specified by the dim argument. In this case, the total size of the input tensor along the specified dimension must be divisible by the desired number of splits. Alternatively, we can provide the desired sizes in a list using the torch.split() function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c077502",
   "metadata": {},
   "source": [
    "Providing the number of splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c76bbc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x17ad9b7ea50>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d8ecf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7576, 0.2793, 0.4031, 0.7347, 0.0293, 0.7999])\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand(6)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f75ca71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_splits = torch.chunk(t, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "533255a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.7576, 0.2793]), tensor([0.4031, 0.7347]), tensor([0.0293, 0.7999]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7eb8e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.7576316 , 0.27931088], dtype=float32),\n",
       " array([0.40306926, 0.73468447], dtype=float32),\n",
       " array([0.02928156, 0.7998586 ], dtype=float32)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item.numpy() for item in t_splits]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0c0436",
   "metadata": {},
   "source": [
    "A tensor of size 6, was divided into a list of 3 tensors, each with size 2. If the tensor isn't divisible by the chunks value, then the last chunk will be smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fecd6a",
   "metadata": {},
   "source": [
    "Providing the sizes of different splits:\n",
    "- Alternatively, instead of defining the number of splits, we can also specify the sizes of output tensors directly. Here, we're splitting a tensor of size 5 into tensors of size 3 and 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d50a51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x17ad9b7ea50>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af6bddcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7576, 0.2793, 0.4031, 0.7347, 0.0293])\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand(5)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30148477",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_splits = torch.split(t, split_size_or_sections=[3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "017836fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.7576, 0.2793, 0.4031]), tensor([0.7347, 0.0293]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a0f7190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.7576316 , 0.27931088, 0.40306926], dtype=float32),\n",
       " array([0.73468447, 0.02928156], dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item.numpy() for item in t_splits]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f033741",
   "metadata": {},
   "source": [
    "Sometimes:\n",
    "- we're working with multiple tensors and need to concatenate or stack them to create a single tensor. In this case, pytorch's functions such as stack() and cat() come in handy. For example, let's create a 1D tensor, A, containing 1s with size 3, a 1D tensor B, containing 0s with size 2, and concatenate them into a 1D tensor C, of size 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c774f9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "A = torch.ones(3)\n",
    "B = torch.zeros(2)\n",
    "C = torch.cat([A,B], axis=0)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0013d1f9",
   "metadata": {},
   "source": [
    "If we create 1D tensors A and B, both with size 3, then we can stack them together to form a 2D tensor S:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0808581b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.ones(3)\n",
    "B = torch.zeros(3)\n",
    "S = torch.stack([A,B], axis=1)\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e104404f",
   "metadata": {},
   "source": [
    "**Building Input Pipelines in PyTorch:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea282eeb",
   "metadata": {},
   "source": [
    "- torch.nn is a module for building NN models. In cases where the training dataset is rather small and can be loaded as a tensor into memory, we can directly use this tensor for training. In typical usecases, however, when the dataset is too large to fit into computer memory, we will need to load the data from the main storage device in chunks, that is, batch by batch. In addition, we may need to construct a data-processing pipeline to apply certain transformations and preprocessing steps to our data, such as mean centering, scaling, or adding noise to augment the training procedure and to prevent overfitting. \n",
    "- Applying preprocessing functions manually everytime can be quite cumbersome. Luckily, pytorch provides a special class for constructing efficient and convenient preprocessing pipelines. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded2d682",
   "metadata": {},
   "source": [
    "**Creating a PyTorch DataLoader from existing tensors:**\n",
    "- If the data already exists in the form of a tensor object, a Python list, or a numpy array, we can easily create a dataset loader using the torch.utils.data.DataLoader() class. It returns an object of the dataloader class, which we can use to iterate through the individual elements of the input dataset. As a simple example, consider the following code, which creates a dataset from a list of values from 0 to 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6b8d3921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5bc0f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.arange(6, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "21c46737",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8114dda0",
   "metadata": {},
   "source": [
    "we can easily iterate through a dataset entry by entry as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86599134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.])\n",
      "tensor([1.])\n",
      "tensor([2.])\n",
      "tensor([3.])\n",
      "tensor([4.])\n",
      "tensor([5.])\n"
     ]
    }
   ],
   "source": [
    "for item in data_loader:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caf0df8",
   "metadata": {},
   "source": [
    "If we want to create batches from this dataset, with a desired batch size of 3, we can do this with the batch-size argument as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cfc328be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(t, batch_size=3, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "73d86d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1: tensor([0., 1., 2.])\n",
      "batch 2: tensor([3., 4., 5.])\n"
     ]
    }
   ],
   "source": [
    "for i,batch in enumerate(data_loader,1):\n",
    "    print(f'batch {i}:',batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b0f2dc",
   "metadata": {},
   "source": [
    "We can always iterate through a dataset directly, but as you saw, DataLoader provides an automatic and customizable batching to a dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95bdaeb",
   "metadata": {},
   "source": [
    "**Combining two tensors into a joint dataset:**\n",
    "- Often, we may have the data in two (or possibly more) tensors. For example, we could have a tensor for features and a tensor for labels. In such cases we need to build a dataset that combines these tensors, which will allow us to retreive the elements of these tensors in tuples. \n",
    "- Assume we have two tensors, t_x, and t_y. Tensor t_x holds our feature values, each of size 3, and t_y stores the class labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c6fdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "t_x = torch.rand([4,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48557b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to unpivot columns in a panda dataframe\n",
    "def unpivot(t):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
