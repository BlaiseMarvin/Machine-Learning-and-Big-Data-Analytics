{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e7ff5dd",
   "metadata": {},
   "source": [
    "RNNs in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39de6f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03237ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "rnn_layer = nn.RNN(input_size=5, hidden_size=2, num_layers=1, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2987682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_xh = rnn_layer.weight_ih_l0\n",
    "w_hh = rnn_layer.weight_hh_l0\n",
    "b_xh = rnn_layer.bias_ih_l0\n",
    "b_hh = rnn_layer.bias_hh_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a1390fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_xh shape:  torch.Size([2, 5])\n",
      "W_hh shape:  torch.Size([2, 2])\n",
      "b_xh shape:  torch.Size([2])\n",
      "b_hh shape:  torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print('W_xh shape: ', w_xh.shape)\n",
    "print('W_hh shape: ', w_hh.shape)\n",
    "print('b_xh shape: ', b_xh.shape)\n",
    "print('b_hh shape: ', b_hh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f998033",
   "metadata": {},
   "source": [
    "The input shape for this layer is (batch_size, sequence_length, 5), first dimension is the batch dimension (as we set batch_first to True), the second dimension corresponds to the sequence, and the last dimension corresponds to the features. Now, we call a forward pass on the rnn and manually compute the outputs at each time step and compare them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba8bbe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_seq = torch.tensor([[1.0]*5, [2.0]*5, [3.0]*5]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "325f6fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5b0997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_seq = torch.reshape(x_seq, (1,3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "635280c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hn = rnn_layer(x_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "167a68bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91aedf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4064662d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8649,  0.9047]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(hn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9152b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 0 =>\n",
      " Input  : [[1. 1. 1. 1. 1.]]\n",
      " Hidden : [[-0.47019297  0.58639044]]\n",
      " Output (manual):  [[-0.35198015  0.52525216]]\n",
      " RNN output:  [[-0.3519801   0.52525216]]\n",
      "\n",
      "Time step 1 =>\n",
      " Input  : [[2. 2. 2. 2. 2.]]\n",
      " Hidden : [[-0.8888316  1.2364398]]\n",
      " Output (manual):  [[-0.68424344  0.76074266]]\n",
      " RNN output:  [[-0.68424344  0.76074266]]\n",
      "\n",
      "Time step 2 =>\n",
      " Input  : [[3. 3. 3. 3. 3.]]\n",
      " Hidden : [[-1.3074702  1.8864892]]\n",
      " Output (manual):  [[-0.8649416  0.9046636]]\n",
      " RNN output:  [[-0.8649416  0.9046636]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# manually computing the output\n",
    "\n",
    "out_man = []\n",
    "\n",
    "for t in range(3):\n",
    "    xt = x_seq[:,t,:]\n",
    "    print(f'Time step {t} =>')\n",
    "    print(' Input  :', xt.numpy())\n",
    "\n",
    "    ht = torch.matmul(xt, torch.transpose(w_xh, 0,1)) + b_xh\n",
    "    print(' Hidden :', ht.detach().numpy())\n",
    "    if t>0:\n",
    "        prev_h = out_man[t-1]\n",
    "    else:\n",
    "        prev_h = torch.zeros((ht.shape))\n",
    "    ot = ht + torch.matmul(prev_h, torch.transpose(w_hh, 0, 1)) + b_hh\n",
    "    ot = torch.tanh(ot)\n",
    "    out_man.append(ot)\n",
    "    print(' Output (manual): ', ot.detach().numpy())\n",
    "    print(' RNN output: ', output[:,t].detach().numpy())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c550e2ff",
   "metadata": {},
   "source": [
    "In our manual forward config, we used the hyberbolic tangent (tanh) activation function since its also used in RNNs (the default activation). As you can see from the printed results, the outputs from the manual forward computations exactly match the outputs of the RNN layer at each time step. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c8125e",
   "metadata": {},
   "source": [
    "**The challenges of learning long-range interactions:**\n",
    "- Come across vanishing and exploding gradients\n",
    "- In practice, there's at least 3 solutions to this problem:\n",
    "  - Gradient Clipping\n",
    "  - Truncated backpropagation through time (TBPTT)\n",
    "  - LSTM\n",
    "- Using gradient clipping, we specify a cut-off or threshold value for the gradients, and we assign this cut-off value to gradient values that exceed this value. In contrast, TBPTT simply limits the number of timesteps that the signal can backpropagate after each forward pass. For example, even if the signal has 100 elements or steps, we may only backpropagate the most recent 20 time steps. \n",
    "While both gradient clipping and tbptt can solve the exploding gradient problem, the truncation limits the number of steps that the gradient can effectively flow back and properly update the weights. On the other hand, LSTMs have been more successful in vanishing and exploding gradient problems while modeling long-range dependencies through the use of memory cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7266e9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
