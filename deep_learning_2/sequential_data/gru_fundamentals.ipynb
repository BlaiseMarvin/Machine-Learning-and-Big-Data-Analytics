{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eacbcf13",
   "metadata": {},
   "source": [
    "**Implementing a GRU from scratch:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e79b4164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11da921b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e2c1a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11da921b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a7704",
   "metadata": {},
   "source": [
    "Defining a custom layers, whose weights will be used for comparison inside the manual implementation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a4bc08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_layer = nn.GRU(input_size=5, hidden_size=2, num_layers=1, batch_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b89d77b",
   "metadata": {},
   "source": [
    "Inspecting the GRU's variables - weights and biases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3ea5f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "wi = gru_layer.weight_ih_l0 # translates to these weights: ((W_ir|W_iz|W_in))\n",
    "wh = gru_layer.weight_hh_l0 # translates to these weights: ((W_hr|W_hz|W_hn))\n",
    "bi = gru_layer.bias_ih_l0 \n",
    "bh = gru_layer.bias_hh_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94437674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 5]), torch.Size([6, 2]), torch.Size([6]), torch.Size([6]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wi.shape, wh.shape, bi.shape, bh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606b18e1",
   "metadata": {},
   "source": [
    "Weight matrix shapes all check out - they're all that way because of the 3 gates that need servicing - hence the input feature dimension of 2 => multiplied by 3 to cater for all these gates. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8b0777",
   "metadata": {},
   "source": [
    "Creating an input sequence to apply these inputs to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "267a280d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_seq = torch.tensor([[1.0]*5,[2.0]*5,[3.0]*5]).unsqueeze(0).float()\n",
    "x_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62eb8693",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, h_n = gru_layer(x_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1e887df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 2]) torch.Size([1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "print(output.shape, h_n.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49373a41",
   "metadata": {},
   "source": [
    "Now, working out the GRU output manually......\n",
    "- for all 3 gates, the linear regression operation is performed using the input and hidden weights and biases on the same inputs and previous memory output. Activatopms are then applied. Can do this...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ea2c2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_state = []\n",
    "\n",
    "# using the dense/linear layer to mimic the linear regression operation between the inputs and the gates\n",
    "# output dimension is 6 - 2 dimensions for each of the 3 gates as detailed in the pytorch gru explanation -> r, z, and n\n",
    "input_gates = nn.Linear(5,6)\n",
    "input_gates.weight.data = wi\n",
    "input_gates.bias.data = bi\n",
    "\n",
    "# using the dense/linear layer to mimic the linear regression operation between the prev input and the gates\n",
    "hidden_gates = nn.Linear(2,6)\n",
    "hidden_gates.weight.data = wh\n",
    "hidden_gates.bias.data = bh\n",
    "\n",
    "# remember that in sequence models, weights are shared across all timesteps:\n",
    "out = []\n",
    "for t in range(3):\n",
    "    xt = x_seq[:,t,:] # get the input that corresponds to timestep t\n",
    "    # compute the input - gates matrix multiplication\n",
    "    ig = input_gates(xt)\n",
    "    if t > 0:\n",
    "        prev_h = out[t-1]\n",
    "    else:\n",
    "        prev_h = torch.zeros((xt.shape[0],2))\n",
    "    \n",
    "    hg = hidden_gates(prev_h)\n",
    "\n",
    "    rgate = torch.sigmoid(ig[:,:2]+hg[:,:2])\n",
    "    zgate = torch.sigmoid(ig[:,2:4]+hg[:,2:4])\n",
    "    ngate = torch.tanh(ig[:,4:] + (rgate*hg[:,4:]))\n",
    "\n",
    "    h = (1-zgate)*ngate + zgate*prev_h\n",
    "    out.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e8b92c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_output = torch.stack(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd1f47d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6458,  0.1718],\n",
       "         [-0.8509,  0.2851],\n",
       "         [-0.9287,  0.3488]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb9315de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6458,  0.1718],\n",
       "         [-0.8509,  0.2851],\n",
       "         [-0.9287,  0.3488]]], grad_fn=<TransposeBackward1>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25490d7",
   "metadata": {},
   "source": [
    "As seen above, the manual output and the output computed using the actual gru layer are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1587de9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's h_n = tensor([[[-0.9287,  0.3488]]], grad_fn=<StackBackward0>)\n",
      "Manual output's h_n = tensor([[-0.9287,  0.3488]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f'Model\\'s h_n = {h_n}')\n",
    "print(f'Manual output\\'s h_n = {out[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09559e8c",
   "metadata": {},
   "source": [
    "We could instead of having the manually created linear layers have a gru cell instead which is nice and clean:\n",
    "- downside though is for layer normalization implementation - we can't fix this inside the gru cell and would have to use our own custom cell\n",
    "- nevertheless, lets explore the default gru cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9379c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_cell = nn.GRUCell(input_size=5, hidden_size=2, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552bb541",
   "metadata": {},
   "source": [
    "Initialize the weights of the gru cell using the initial gru layer weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba7539cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_cell.weight_ih.data = wi\n",
    "gru_cell.weight_hh.data = wh\n",
    "gru_cell.bias_ih.data = bi\n",
    "gru_cell.bias_hh.data = bh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d788b88",
   "metadata": {},
   "source": [
    "Compute the sequence output using this gru cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "542dc0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_state = []\n",
    "\n",
    "for t in range(3):\n",
    "    xt = x_seq[:, t, :]\n",
    "\n",
    "    if t > 0:\n",
    "        prev_h = cell_state[t-1]\n",
    "    else:\n",
    "        prev_h = torch.zeros((xt.shape[0],2))\n",
    "    h = gru_cell(xt,prev_h)\n",
    "    cell_state.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d3bf7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_out = torch.stack(cell_state, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "395e669c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6458,  0.1718],\n",
       "         [-0.8509,  0.2851],\n",
       "         [-0.9287,  0.3488]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fc7c7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6458,  0.1718],\n",
       "         [-0.8509,  0.2851],\n",
       "         [-0.9287,  0.3488]]], grad_fn=<TransposeBackward1>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d591fb0b",
   "metadata": {},
   "source": [
    "Same output for both the gru cell and the gru layer....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e6d5cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now creating a custom GRU Cell... capable of accepting and computing layer normalization\n",
    "\n",
    "class CustomGRUCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(input_size, 3*hidden_size)\n",
    "        self.hidden = nn.Linear(hidden_size, 3*hidden_size)\n",
    "        self.hidden_size = hidden_size\n",
    "    def forward(self, x, prev_h):\n",
    "        computed_inputs = self.input(x)\n",
    "        computed_hiddens = self.hidden(prev_h)\n",
    "        \n",
    "        # gates.....\n",
    "        rgate = torch.sigmoid(computed_inputs[:,:self.hidden_size]+computed_hiddens[:,:self.hidden_size])\n",
    "        zgate = torch.sigmoid(computed_inputs[:,self.hidden_size:2*self.hidden_size]+computed_hiddens[:,self.hidden_size:2*self.hidden_size])\n",
    "        ngate = torch.tanh(computed_inputs[:,2*self.hidden_size:]+(rgate*computed_hiddens[:,2*self.hidden_size:]))\n",
    "        h = (1-zgate)*ngate + zgate*prev_h\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e8c13ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_cell = CustomGRUCell(5,2)\n",
    "cust_cell.input.weight.data = wi\n",
    "cust_cell.input.bias.data = bi\n",
    "cust_cell.hidden.weight.data = wh\n",
    "cust_cell.hidden.bias.data = bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b19e185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_state2 = []\n",
    "\n",
    "for t in range(3):\n",
    "    xt = x_seq[:,t,:]\n",
    "    if t > 0:\n",
    "        prev_h = cell_state2[t-1]\n",
    "    else:\n",
    "        prev_h = torch.zeros((xt.shape[0],2))\n",
    "    h = cust_cell(xt, prev_h)\n",
    "    cell_state2.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9297e06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6458,  0.1718],\n",
       "         [-0.8509,  0.2851],\n",
       "         [-0.9287,  0.3488]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(cell_state2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae623eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6458,  0.1718],\n",
       "         [-0.8509,  0.2851],\n",
       "         [-0.9287,  0.3488]]], grad_fn=<TransposeBackward1>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36646f0c",
   "metadata": {},
   "source": [
    "Bingo......"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7bb762",
   "metadata": {},
   "source": [
    "Now, custom GRU Cell with Layer Normalization...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d857eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGRUCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(input_size, 3*hidden_size)\n",
    "        self.hidden = nn.Linear(hidden_size, 3*hidden_size)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        #Â one layer norm per gate.. best practice\n",
    "        self.ln_r = nn.LayerNorm(hidden_size)\n",
    "        self.ln_z = nn.LayerNorm(hidden_size)\n",
    "        self.ln_n = nn.LayerNorm(hidden_size)\n",
    "    def forward(self, x, prev_h):\n",
    "        computed_inputs = self.input(x)\n",
    "        computed_hiddens = self.hidden(prev_h)\n",
    "        \n",
    "        # gates.....\n",
    "        pre_r = computed_inputs[:,:self.hidden_size]+computed_hiddens[:,:self.hidden_size]\n",
    "        rgate = torch.sigmoid(self.ln_r(pre_r))\n",
    "\n",
    "        pre_z = computed_inputs[:,self.hidden_size:2*self.hidden_size]+computed_hiddens[:,self.hidden_size:2*self.hidden_size]\n",
    "        zgate = torch.sigmoid(self.ln_z(pre_z))\n",
    "\n",
    "        pre_n = computed_inputs[:,2*self.hidden_size:]+(rgate*computed_hiddens[:,2*self.hidden_size:])\n",
    "        ngate = torch.tanh(self.ln_n(pre_n))\n",
    "        h = (1-zgate)*ngate + zgate*prev_h\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fe8d3b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d161bca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
