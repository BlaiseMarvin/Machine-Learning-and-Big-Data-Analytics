{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e012b28",
   "metadata": {},
   "source": [
    "Implementing a sequence to sequence timeseries forecasting model using a GRU with custom gru cells and layer cells with layer normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eee7107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.fetch_data import fetch_timeseries_data\n",
    "from utils.load_data import TimeSeriesDataset\n",
    "from utils.early_stopping import EarlyStopping\n",
    "from utils.fetch_data import create_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3011c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10e642110>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c52dd",
   "metadata": {},
   "source": [
    "Get the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35f53ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fetch_timeseries_data()\n",
    "\n",
    "# create the training, validation, and test splits:\n",
    "rail_train, rail_valid, rail_test = create_splits(df, attr='rail', train_ran=['2016-01','2024-12'],val_ran=['2025-01','2025-04'],test_ran=['2025-05'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00a242d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 56\n",
    "forecasting_horizon = 14\n",
    "\n",
    "def create_x_chunks(ds):\n",
    "    return [ds[i:i+seq_length] for i in range(len(ds)-seq_length-forecasting_horizon+1)]\n",
    "\n",
    "def create_y_chunks(ds):\n",
    "    y_chunks = []\n",
    "    for i in range(len(ds)-seq_length-forecasting_horizon+1):\n",
    "        seq_chunk = [ds[i+j+1:i+j+1+forecasting_horizon] for j in range(seq_length)] # for each element in the sequence, get the next 14 values\n",
    "        y_chunks.append(seq_chunk)\n",
    "    return y_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "432e288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_chunks, train_y_chunks = create_x_chunks(rail_train.values.tolist()), create_y_chunks(rail_train.values.tolist())\n",
    "valid_x_chunks, valid_y_chunks = create_x_chunks(rail_valid.values.tolist()), create_y_chunks(rail_valid.values.tolist())\n",
    "test_x_chunks, test_y_chunks = create_x_chunks(rail_test.values.tolist()), create_y_chunks(rail_test.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fe05466",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_chunks, train_y_chunks = torch.tensor(train_x_chunks), torch.tensor(train_y_chunks)\n",
    "valid_x_chunks, valid_y_chunks = torch.tensor(valid_x_chunks), torch.tensor(valid_y_chunks)\n",
    "test_x_chunks, test_y_chunks = torch.tensor(test_x_chunks), torch.tensor(test_y_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b0ceafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3219, 56]), torch.Size([3219, 56, 14]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_chunks.shape, train_y_chunks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b54c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TsDataset(Dataset):\n",
    "    def __init__(self, x_chunks, y_chunks):\n",
    "        super().__init__()\n",
    "        self.x_chunks = x_chunks.unsqueeze(2)\n",
    "        self.y_chunks = y_chunks\n",
    "    def __len__(self):\n",
    "        return self.x_chunks.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        x,y = self.x_chunks[index,:,:], self.y_chunks[index,:,:]\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b27a196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TsDataset(train_x_chunks, train_y_chunks)\n",
    "val_ds = TsDataset(valid_x_chunks, valid_y_chunks)\n",
    "test_ds = TsDataset(test_x_chunks, test_y_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "792b670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=128)\n",
    "test_dl = DataLoader(test_ds, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f285201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10e642110>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b35fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGRUCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, device):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(input_size, 3*hidden_size, device=device)\n",
    "        self.hidden = nn.Linear(hidden_size, 3*hidden_size, device=device)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        #Â one layer norm per gate.. best practice\n",
    "        self.ln_r = nn.LayerNorm(hidden_size, device=device)\n",
    "        self.ln_z = nn.LayerNorm(hidden_size, device=device)\n",
    "        self.ln_n = nn.LayerNorm(hidden_size, device=device)\n",
    "    def forward(self, x, prev_h):\n",
    "        computed_inputs = self.input(x)\n",
    "        computed_hiddens = self.hidden(prev_h)\n",
    "        \n",
    "        # gates.....\n",
    "        pre_r = computed_inputs[:,:self.hidden_size]+computed_hiddens[:,:self.hidden_size]\n",
    "        rgate = torch.sigmoid(self.ln_r(pre_r))\n",
    "\n",
    "        pre_z = computed_inputs[:,self.hidden_size:2*self.hidden_size]+computed_hiddens[:,self.hidden_size:2*self.hidden_size]\n",
    "        zgate = torch.sigmoid(self.ln_z(pre_z))\n",
    "\n",
    "        pre_n = computed_inputs[:,2*self.hidden_size:]+(rgate*computed_hiddens[:,2*self.hidden_size:])\n",
    "        ngate = torch.tanh(self.ln_n(pre_n))\n",
    "        h = (1-zgate)*ngate + zgate*prev_h\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d100126",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGRULayer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, device):\n",
    "        super().__init__()\n",
    "        self.gru_cell = CustomGRUCell(input_size, hidden_size,device=device)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "    def forward(self, input_):\n",
    "        input_ = input_.to(device)\n",
    "        batch, seq_len, _ = input_.shape\n",
    "        state = []\n",
    "        prev_h = torch.zeros((batch,self.hidden_size),device=device)\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            xt = input_[:,t,:]\n",
    "            prev_h = self.gru_cell(xt, prev_h)\n",
    "            state.append(prev_h)\n",
    "        out = torch.stack(state, dim=1)\n",
    "        return out, prev_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a1b4c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10e642110>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a5e9514",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqUnivar(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2,device):\n",
    "        super().__init__()\n",
    "        self.gru = CustomGRULayer(input_size, hidden_size1, device=device)\n",
    "        self.gru2 = CustomGRULayer(hidden_size1, hidden_size2, device=device)\n",
    "        self.linear = nn.Linear(hidden_size2, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(64,32)\n",
    "        self.linear3 = nn.Linear(32,14)\n",
    "        self.ln = nn.LayerNorm(128)\n",
    "        self.ln2 = nn.LayerNorm(64)\n",
    "        self.ln3 = nn.LayerNorm(32)\n",
    "        self.ln\n",
    "    def forward(self, input_):\n",
    "        out, prev_h = self.gru(input_)\n",
    "        out, prev_h = self.gru2(out)\n",
    "        out = self.ln(out)\n",
    "        out = self.relu(self.ln2(self.linear(out)))\n",
    "        out = self.relu(self.ln3(self.linear2(out)))\n",
    "        return self.linear3(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a66f0821",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0981b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2SeqUnivar(1, 512, 128, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afb9071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "criterion = nn.HuberLoss(reduction='sum')\n",
    "early_stopper = EarlyStopping(patience=50, checkpoint_path='seq2seq_gru.pt', restore_best_weights=True, verbose=True)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',patience=10, factor=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc39a7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1| Train loss: 31.4188| Val loss: 6.7556\n",
      "Metric improved to 6.7556. Checkpoint saved at epoch 0\n",
      "Epoch: 2| Train loss: 9.7295| Val loss: 3.5199\n",
      "Metric improved to 3.5199. Checkpoint saved at epoch 1\n",
      "Epoch: 3| Train loss: 7.6194| Val loss: 3.5669\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch: 4| Train loss: 7.3285| Val loss: 3.2332\n",
      "Metric improved to 3.2332. Checkpoint saved at epoch 3\n",
      "Epoch: 5| Train loss: 6.7279| Val loss: 3.3579\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch: 6| Train loss: 6.0862| Val loss: 3.2787\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch: 7| Train loss: 5.5389| Val loss: 3.3955\n",
      "No improvement for 3 epoch(s)\n",
      "Epoch: 8| Train loss: 4.4670| Val loss: 3.0381\n",
      "Metric improved to 3.0381. Checkpoint saved at epoch 7\n",
      "Epoch: 9| Train loss: 3.6274| Val loss: 1.9190\n",
      "Metric improved to 1.9190. Checkpoint saved at epoch 8\n",
      "Epoch: 10| Train loss: 3.1422| Val loss: 1.9722\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch: 11| Train loss: 2.9502| Val loss: 1.7964\n",
      "Metric improved to 1.7964. Checkpoint saved at epoch 10\n",
      "Epoch: 12| Train loss: 2.7802| Val loss: 1.7076\n",
      "Metric improved to 1.7076. Checkpoint saved at epoch 11\n",
      "Epoch: 13| Train loss: 2.6919| Val loss: 1.7504\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch: 14| Train loss: 2.7113| Val loss: 1.6475\n",
      "Metric improved to 1.6475. Checkpoint saved at epoch 13\n",
      "Epoch: 15| Train loss: 2.5366| Val loss: 1.6429\n",
      "Metric improved to 1.6429. Checkpoint saved at epoch 14\n",
      "Epoch: 16| Train loss: 2.4502| Val loss: 1.5885\n",
      "Metric improved to 1.5885. Checkpoint saved at epoch 15\n",
      "Epoch: 17| Train loss: 2.4968| Val loss: 1.7623\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch: 18| Train loss: 2.3754| Val loss: 1.7774\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch: 19| Train loss: 2.2984| Val loss: 1.5673\n",
      "Metric improved to 1.5673. Checkpoint saved at epoch 18\n",
      "Epoch: 20| Train loss: 2.2607| Val loss: 1.5315\n",
      "Metric improved to 1.5315. Checkpoint saved at epoch 19\n",
      "Epoch: 21| Train loss: 2.2184| Val loss: 2.2872\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch: 22| Train loss: 2.3484| Val loss: 1.5883\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch: 23| Train loss: 2.1234| Val loss: 1.4517\n",
      "Metric improved to 1.4517. Checkpoint saved at epoch 22\n",
      "Epoch: 24| Train loss: 2.1177| Val loss: 1.4498\n",
      "Metric improved to 1.4498. Checkpoint saved at epoch 23\n",
      "Epoch: 25| Train loss: 2.0201| Val loss: 1.7769\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch: 26| Train loss: 2.0538| Val loss: 1.4751\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch: 27| Train loss: 1.9833| Val loss: 1.4636\n",
      "No improvement for 3 epoch(s)\n",
      "Epoch: 28| Train loss: 1.9451| Val loss: 1.3958\n",
      "Metric improved to 1.3958. Checkpoint saved at epoch 27\n",
      "Epoch: 29| Train loss: 1.9140| Val loss: 1.4869\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch: 30| Train loss: 1.9131| Val loss: 1.4877\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch: 31| Train loss: 1.8510| Val loss: 1.4730\n",
      "No improvement for 3 epoch(s)\n",
      "Epoch: 32| Train loss: 1.8219| Val loss: 1.5868\n",
      "No improvement for 4 epoch(s)\n",
      "Epoch: 33| Train loss: 1.8251| Val loss: 1.2860\n",
      "Metric improved to 1.2860. Checkpoint saved at epoch 32\n",
      "Epoch: 34| Train loss: 1.7783| Val loss: 1.3301\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch: 35| Train loss: 1.6873| Val loss: 1.2908\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch: 36| Train loss: 1.6587| Val loss: 1.3141\n",
      "No improvement for 3 epoch(s)\n",
      "Epoch: 37| Train loss: 1.7361| Val loss: 1.3722\n",
      "No improvement for 4 epoch(s)\n",
      "Epoch: 38| Train loss: 1.6719| Val loss: 1.2768\n",
      "Metric improved to 1.2768. Checkpoint saved at epoch 37\n",
      "Epoch: 39| Train loss: 1.6204| Val loss: 1.2573\n",
      "Metric improved to 1.2573. Checkpoint saved at epoch 38\n",
      "Epoch: 40| Train loss: 1.5973| Val loss: 1.3259\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch: 41| Train loss: 1.5628| Val loss: 1.2873\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch: 42| Train loss: 1.5378| Val loss: 1.2641\n",
      "No improvement for 3 epoch(s)\n",
      "Epoch: 43| Train loss: 1.5118| Val loss: 1.7139\n",
      "No improvement for 4 epoch(s)\n",
      "Epoch: 44| Train loss: 1.4762| Val loss: 1.2521\n",
      "Metric improved to 1.2521. Checkpoint saved at epoch 43\n",
      "Epoch: 45| Train loss: 1.4143| Val loss: 1.2900\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch: 46| Train loss: 1.5112| Val loss: 1.7634\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch: 47| Train loss: 1.5728| Val loss: 1.3300\n",
      "No improvement for 3 epoch(s)\n",
      "Epoch: 48| Train loss: 1.3886| Val loss: 1.2280\n",
      "Metric improved to 1.2280. Checkpoint saved at epoch 47\n",
      "Epoch: 49| Train loss: 1.3231| Val loss: 1.1871\n",
      "Metric improved to 1.1871. Checkpoint saved at epoch 48\n",
      "Epoch: 50| Train loss: 1.3765| Val loss: 1.2600\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch: 51| Train loss: 1.2930| Val loss: 1.1887\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch: 52| Train loss: 1.2424| Val loss: 1.1274\n",
      "Metric improved to 1.1274. Checkpoint saved at epoch 51\n",
      "Epoch: 53| Train loss: 1.2290| Val loss: 1.2951\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch: 54| Train loss: 1.2610| Val loss: 1.2094\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch: 55| Train loss: 1.2912| Val loss: 1.3589\n",
      "No improvement for 3 epoch(s)\n",
      "Epoch: 56| Train loss: 1.2096| Val loss: 1.1580\n",
      "No improvement for 4 epoch(s)\n",
      "Epoch: 57| Train loss: 1.1656| Val loss: 1.2738\n",
      "No improvement for 5 epoch(s)\n",
      "Epoch: 58| Train loss: 1.1388| Val loss: 1.1969\n",
      "No improvement for 6 epoch(s)\n",
      "Epoch: 59| Train loss: 1.1314| Val loss: 1.1669\n",
      "No improvement for 7 epoch(s)\n",
      "Epoch: 60| Train loss: 1.1271| Val loss: 1.1532\n",
      "No improvement for 8 epoch(s)\n",
      "Epoch: 61| Train loss: 1.1121| Val loss: 1.1793\n",
      "No improvement for 9 epoch(s)\n",
      "Epoch: 62| Train loss: 1.1373| Val loss: 1.2537\n",
      "No improvement for 10 epoch(s)\n",
      "Epoch: 63| Train loss: 1.1405| Val loss: 1.1947\n",
      "No improvement for 11 epoch(s)\n",
      "Epoch: 64| Train loss: 1.0611| Val loss: 1.1643\n",
      "No improvement for 12 epoch(s)\n",
      "Epoch: 65| Train loss: 1.0574| Val loss: 1.1998\n",
      "No improvement for 13 epoch(s)\n",
      "Epoch: 66| Train loss: 1.0383| Val loss: 1.2193\n",
      "No improvement for 14 epoch(s)\n",
      "Epoch: 67| Train loss: 1.0380| Val loss: 1.2070\n",
      "No improvement for 15 epoch(s)\n",
      "Epoch: 68| Train loss: 1.0191| Val loss: 1.2459\n",
      "No improvement for 16 epoch(s)\n",
      "Epoch: 69| Train loss: 1.0121| Val loss: 1.1790\n",
      "No improvement for 17 epoch(s)\n",
      "Epoch: 70| Train loss: 1.0136| Val loss: 1.2652\n",
      "No improvement for 18 epoch(s)\n",
      "Epoch: 71| Train loss: 1.0000| Val loss: 1.2216\n",
      "No improvement for 19 epoch(s)\n",
      "Epoch: 72| Train loss: 0.9999| Val loss: 1.1998\n",
      "No improvement for 20 epoch(s)\n",
      "Epoch: 73| Train loss: 0.9843| Val loss: 1.1119\n",
      "Metric improved to 1.1119. Checkpoint saved at epoch 72\n",
      "Epoch: 74| Train loss: 0.9626| Val loss: 1.1593\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch: 75| Train loss: 0.9623| Val loss: 1.1602\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch: 76| Train loss: 0.9779| Val loss: 1.2403\n",
      "No improvement for 3 epoch(s)\n",
      "Epoch: 77| Train loss: 0.9785| Val loss: 1.1178\n",
      "No improvement for 4 epoch(s)\n",
      "Epoch: 78| Train loss: 0.9349| Val loss: 1.1578\n",
      "No improvement for 5 epoch(s)\n",
      "Epoch: 79| Train loss: 0.9556| Val loss: 1.1584\n",
      "No improvement for 6 epoch(s)\n",
      "Epoch: 80| Train loss: 0.9398| Val loss: 1.1111\n",
      "Metric improved to 1.1111. Checkpoint saved at epoch 79\n",
      "Epoch: 81| Train loss: 0.9171| Val loss: 1.1953\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch: 82| Train loss: 0.9156| Val loss: 1.1880\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch: 83| Train loss: 0.9229| Val loss: 1.3060\n",
      "No improvement for 3 epoch(s)\n",
      "Epoch: 84| Train loss: 0.9421| Val loss: 1.1448\n",
      "No improvement for 4 epoch(s)\n",
      "Epoch: 85| Train loss: 0.9094| Val loss: 1.1675\n",
      "No improvement for 5 epoch(s)\n",
      "Epoch: 86| Train loss: 0.9168| Val loss: 1.3649\n",
      "No improvement for 6 epoch(s)\n",
      "Epoch: 87| Train loss: 0.9069| Val loss: 1.1624\n",
      "No improvement for 7 epoch(s)\n",
      "Epoch: 88| Train loss: 0.8769| Val loss: 1.1599\n",
      "No improvement for 8 epoch(s)\n",
      "Epoch: 89| Train loss: 0.8660| Val loss: 1.1281\n",
      "No improvement for 9 epoch(s)\n",
      "Epoch: 90| Train loss: 0.8693| Val loss: 1.1970\n",
      "No improvement for 10 epoch(s)\n",
      "Epoch: 91| Train loss: 0.8701| Val loss: 1.2261\n",
      "No improvement for 11 epoch(s)\n",
      "Epoch: 92| Train loss: 0.8609| Val loss: 1.2237\n",
      "No improvement for 12 epoch(s)\n",
      "Epoch: 93| Train loss: 0.8452| Val loss: 1.1774\n",
      "No improvement for 13 epoch(s)\n",
      "Epoch: 94| Train loss: 0.8473| Val loss: 1.2077\n",
      "No improvement for 14 epoch(s)\n",
      "Epoch: 95| Train loss: 0.8906| Val loss: 1.1569\n",
      "No improvement for 15 epoch(s)\n",
      "Epoch: 96| Train loss: 0.8478| Val loss: 1.1911\n",
      "No improvement for 16 epoch(s)\n",
      "Epoch: 97| Train loss: 0.8325| Val loss: 1.1404\n",
      "No improvement for 17 epoch(s)\n",
      "Epoch: 98| Train loss: 0.8156| Val loss: 1.1958\n",
      "No improvement for 18 epoch(s)\n",
      "Epoch: 99| Train loss: 0.8194| Val loss: 1.1905\n",
      "No improvement for 19 epoch(s)\n",
      "Epoch: 100| Train loss: 0.8291| Val loss: 1.3478\n",
      "No improvement for 20 epoch(s)\n",
      "Epoch: 101| Train loss: 0.8856| Val loss: 1.3254\n",
      "No improvement for 21 epoch(s)\n",
      "Epoch: 102| Train loss: 0.8881| Val loss: 1.1297\n",
      "No improvement for 22 epoch(s)\n",
      "Epoch: 103| Train loss: 0.8241| Val loss: 1.2871\n",
      "No improvement for 23 epoch(s)\n",
      "Epoch: 104| Train loss: 0.8004| Val loss: 1.2353\n",
      "No improvement for 24 epoch(s)\n",
      "Epoch: 105| Train loss: 0.8128| Val loss: 1.3198\n",
      "No improvement for 25 epoch(s)\n",
      "Epoch: 106| Train loss: 0.8236| Val loss: 1.2899\n",
      "No improvement for 26 epoch(s)\n",
      "Epoch: 107| Train loss: 0.7847| Val loss: 1.1683\n",
      "No improvement for 27 epoch(s)\n",
      "Epoch: 108| Train loss: 0.7853| Val loss: 1.2143\n",
      "No improvement for 28 epoch(s)\n",
      "Epoch: 109| Train loss: 0.7887| Val loss: 1.1881\n",
      "No improvement for 29 epoch(s)\n",
      "Epoch: 110| Train loss: 0.8627| Val loss: 1.2626\n",
      "No improvement for 30 epoch(s)\n",
      "Epoch: 111| Train loss: 0.8231| Val loss: 1.2080\n",
      "No improvement for 31 epoch(s)\n",
      "Epoch: 112| Train loss: 0.7953| Val loss: 1.2481\n",
      "No improvement for 32 epoch(s)\n",
      "Epoch: 113| Train loss: 0.7783| Val loss: 1.1876\n",
      "No improvement for 33 epoch(s)\n",
      "Epoch: 114| Train loss: 0.7645| Val loss: 1.2215\n",
      "No improvement for 34 epoch(s)\n",
      "Epoch: 115| Train loss: 0.7560| Val loss: 1.2170\n",
      "No improvement for 35 epoch(s)\n",
      "Epoch: 116| Train loss: 0.7483| Val loss: 1.2032\n",
      "No improvement for 36 epoch(s)\n",
      "Epoch: 117| Train loss: 0.7465| Val loss: 1.2143\n",
      "No improvement for 37 epoch(s)\n",
      "Epoch: 118| Train loss: 0.7498| Val loss: 1.2075\n",
      "No improvement for 38 epoch(s)\n",
      "Epoch: 119| Train loss: 0.7532| Val loss: 1.2570\n",
      "No improvement for 39 epoch(s)\n",
      "Epoch: 120| Train loss: 0.7514| Val loss: 1.1763\n",
      "No improvement for 40 epoch(s)\n",
      "Epoch: 121| Train loss: 0.7707| Val loss: 1.2179\n",
      "No improvement for 41 epoch(s)\n",
      "Epoch: 122| Train loss: 0.7736| Val loss: 1.2050\n",
      "No improvement for 42 epoch(s)\n",
      "Epoch: 123| Train loss: 0.7456| Val loss: 1.1815\n",
      "No improvement for 43 epoch(s)\n",
      "Epoch: 124| Train loss: 0.7369| Val loss: 1.3304\n",
      "No improvement for 44 epoch(s)\n",
      "Epoch: 125| Train loss: 0.7450| Val loss: 1.1629\n",
      "No improvement for 45 epoch(s)\n",
      "Epoch: 126| Train loss: 0.7325| Val loss: 1.2210\n",
      "No improvement for 46 epoch(s)\n",
      "Epoch: 127| Train loss: 0.7261| Val loss: 1.1994\n",
      "No improvement for 47 epoch(s)\n",
      "Epoch: 128| Train loss: 0.7209| Val loss: 1.2278\n",
      "No improvement for 48 epoch(s)\n",
      "Epoch: 129| Train loss: 0.7218| Val loss: 1.2906\n",
      "No improvement for 49 epoch(s)\n",
      "Epoch: 130| Train loss: 0.7245| Val loss: 1.2328\n",
      "No improvement for 50 epoch(s)\n",
      "Early stopping triggered after 50 epochs of no improvement\n",
      "Restored best model and optimizer states from checkpoint\n",
      "Stopping at epoch: 130\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = [0] * n_epochs\n",
    "val_loss = [0] * n_epochs\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    # iterate through the training data\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x_batch)\n",
    "        # adding l1 norm\n",
    "        norm = sum(p.abs().sum() for p in model.parameters())\n",
    "        loss = criterion(out, y_batch) + 1e-3*norm\n",
    "        loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), 2.0)\n",
    "        optimizer.step()\n",
    "        train_loss[epoch]+=loss.item()\n",
    "    train_loss[epoch] /= len(train_dl.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_batch,y_batch in val_dl:\n",
    "            x_batch,y_batch = x_batch.to(device),y_batch.to(device)\n",
    "            out = model(x_batch)\n",
    "            loss = criterion(out, y_batch)\n",
    "            val_loss[epoch] += loss.item()\n",
    "        val_loss[epoch] /= len(val_dl.dataset)\n",
    "\n",
    "        scheduler.step(val_loss[epoch])\n",
    "        print(f'Epoch: {epoch+1}| Train loss: {train_loss[epoch]:.4f}| Val loss: {val_loss[epoch]:.4f}')\n",
    "        early_stopper(val_loss[epoch], model, optimizer, epoch)\n",
    "        if early_stopper.should_stop:\n",
    "            print(f\"Stopping at epoch: {epoch+1}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fdbcd5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_loss = nn.L1Loss(reduction='mean')\n",
    "loss_ = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for x_batch, y_batch in test_dl:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        out = model(x_batch)\n",
    "        loss = l1_loss(out, y_batch)\n",
    "        loss_.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67c087e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29856.85132443905"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum(loss_)/len(loss_)) * 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50e8bee",
   "metadata": {},
   "source": [
    "GRU has the best performance overall for this task"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
