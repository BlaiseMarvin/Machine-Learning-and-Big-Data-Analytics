{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdcf3abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from torch.utils.data import random_split\n",
    "import re \n",
    "from collections import Counter, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1962bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e347bbc",
   "metadata": {},
   "source": [
    "**Project one - predicting the sentiment of IMDb movie reviews:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c89744",
   "metadata": {},
   "source": [
    "Sentiment analysis is concerned with analysing the expressed opinion of a sentence or text document. Following section: we implement a multilayer RNN for sentiment analysis using a many-to-one architecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c14c894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', transform = None):\n",
    "        self.samples = []\n",
    "        self.transform = transform \n",
    "\n",
    "        combined_path = os.path.join(root_dir,split)\n",
    "        for label_name in ['pos','neg']:\n",
    "            label_dir = os.path.join(combined_path, label_name)\n",
    "            label = 1 if label_name == 'pos' else 0\n",
    "            for fname in os.listdir(label_dir):\n",
    "                if fname.endswith('.txt'):\n",
    "                    path = os.path.join(label_dir, fname)\n",
    "                    self.samples.append((path, label))\n",
    "        random.shuffle(self.samples)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        if self.transform:\n",
    "            text = self.transform(text)\n",
    "        return text, label    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0e2ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/Users/blaise/Documents/ML/Machine-Learning-and-Big-Data-Analytics/data/aclImdb\"\n",
    "train_dataset = TextDataset(root_dir=root_dir, split='train')\n",
    "test_dataset = TextDataset(root_dir=root_dir, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f388cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2e423a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('This \"movie\" is such a bad work! Nothing seems to even try and be realistic. Plot is weak, acting - miserable, actors wondering around like in a 1st year production, trying very hard to act with no chance at all from the beginning. What a flop! What a waste of time, money and effort to all concerned including the audience. Well, as in any thriller, here too are murders, corpses and blood. Just imagine someone who 5 minutes ago, committed a murder with a knife, and came out calm and smiling, not to mention clean as a whistle, as if slashing one\\'s throat is done by a virtual agent. Also, this murder was supposed to be done by a tiny fragile woman on a high strong male, and she cut his throat!!! Did she ask him, politely, to bend down for her? Much more stupidity of that same kind is going on and on leaving the audience wondering if this meant to be a joke which just turned out to be a bad one. Continuity is another huge problem as for instance: The eager-hungry groom is lying in bed, waiting for his virgin-bride to get out of the bathroom and after a long while, falls asleep(!?!). Next scene opens with the young couple entering the reception-area, asking for guidance to scenery spots! NOT A WORD ABOUT LAST NIGHT??? Such a waste of time even to try and write about this low-low supposed-to-be \"movie\".',\n",
       " 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ebb806",
   "metadata": {},
   "source": [
    "Creating a validation set from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02465c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = random_split(train_dataset, [20000,5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad417c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 5000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3b6c69",
   "metadata": {},
   "source": [
    "To prepare the data for input to a NN, we need to encode it to numeric values. We need to find the unique words(tokens) in the training dataset. We will use the python Counter class to find the unique tokens in the text. We are only interested in the unique word and won't require word counts as in BoW (Bag of Words) models. word counts here are created as a side product. To split the text into words - we will use a tokenizer function, which also cleans up the text, removing html markups, as well as punctuation and other non-letter characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aea66ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\w'\n",
      "/var/folders/_h/yzv4_kzj2yv3z5xh7lks3hpr0000gn/T/ipykernel_9387/2878062256.py:3: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
      "/var/folders/_h/yzv4_kzj2yv3z5xh7lks3hpr0000gn/T/ipykernel_9387/2878062256.py:4: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  text = re.sub(\"[^\\w']+\",' ', text.lower()) + ' ' +' '.join(emoticons).replace('-','')\n"
     ]
    }
   ],
   "source": [
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>','', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub(\"[^\\w']+\",' ', text.lower()) + ' ' +' '.join(emoticons).replace('-','')\n",
    "    tokenized = text.split()\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "206d0952",
   "metadata": {},
   "outputs": [],
   "source": [
    "line, label = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b1d4dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My first review of 2010 is \"Into The Blue 2: The Reef\". The story is about two divers played by Chris Carmack and Laura Vandervoort who love to explore hidden treasures at a bottom of a local reef. One day after a day of exploring they are approached by a couple played by David Anders and Marsha Thomason. They tell the young divers that they want to hire them to explore the reef and find a rare artifact about Columbus\\' hidden treasure that is reported at the bottom of the reef.<br /><br />Next day the four dive to the bottom of the reef and of coarse after a whole day of diving they find nothing. A few more days past and the two hired divers found out that they a part of a major deadly plot in which they can\\'t escape otherwise they will be killed. They were hired to find two big containers. One contains a nuclear reactor and the other contains a core.<br /><br />The movie also has a back story about another person (brother of the lead character) trying to patch things up with his girlfriend, I reckon this part of the story was a waste of time, this also includes a very steamy sex scene between the couple which to me is a complete waste and wasn\\'t needed to be shown.<br /><br />However apart from that, this movie does have some good underwater photography and the colors blend in well which is why it receives 4 stars. Into The Blue 2 is a sequel only by name. None of the original actors or characters return, it has a dumb plot, stupid characters and a boring climax.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fec66160",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cb49556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my',\n",
       " 'first',\n",
       " 'review',\n",
       " 'of',\n",
       " '2010',\n",
       " 'is',\n",
       " 'into',\n",
       " 'the',\n",
       " 'blue',\n",
       " '2',\n",
       " 'the',\n",
       " 'reef',\n",
       " 'the',\n",
       " 'story',\n",
       " 'is',\n",
       " 'about',\n",
       " 'two',\n",
       " 'divers',\n",
       " 'played',\n",
       " 'by',\n",
       " 'chris',\n",
       " 'carmack',\n",
       " 'and',\n",
       " 'laura',\n",
       " 'vandervoort',\n",
       " 'who',\n",
       " 'love',\n",
       " 'to',\n",
       " 'explore',\n",
       " 'hidden',\n",
       " 'treasures',\n",
       " 'at',\n",
       " 'a',\n",
       " 'bottom',\n",
       " 'of',\n",
       " 'a',\n",
       " 'local',\n",
       " 'reef',\n",
       " 'one',\n",
       " 'day',\n",
       " 'after',\n",
       " 'a',\n",
       " 'day',\n",
       " 'of',\n",
       " 'exploring',\n",
       " 'they',\n",
       " 'are',\n",
       " 'approached',\n",
       " 'by',\n",
       " 'a',\n",
       " 'couple',\n",
       " 'played',\n",
       " 'by',\n",
       " 'david',\n",
       " 'anders',\n",
       " 'and',\n",
       " 'marsha',\n",
       " 'thomason',\n",
       " 'they',\n",
       " 'tell',\n",
       " 'the',\n",
       " 'young',\n",
       " 'divers',\n",
       " 'that',\n",
       " 'they',\n",
       " 'want',\n",
       " 'to',\n",
       " 'hire',\n",
       " 'them',\n",
       " 'to',\n",
       " 'explore',\n",
       " 'the',\n",
       " 'reef',\n",
       " 'and',\n",
       " 'find',\n",
       " 'a',\n",
       " 'rare',\n",
       " 'artifact',\n",
       " 'about',\n",
       " \"columbus'\",\n",
       " 'hidden',\n",
       " 'treasure',\n",
       " 'that',\n",
       " 'is',\n",
       " 'reported',\n",
       " 'at',\n",
       " 'the',\n",
       " 'bottom',\n",
       " 'of',\n",
       " 'the',\n",
       " 'reef',\n",
       " 'next',\n",
       " 'day',\n",
       " 'the',\n",
       " 'four',\n",
       " 'dive',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bottom',\n",
       " 'of',\n",
       " 'the',\n",
       " 'reef',\n",
       " 'and',\n",
       " 'of',\n",
       " 'coarse',\n",
       " 'after',\n",
       " 'a',\n",
       " 'whole',\n",
       " 'day',\n",
       " 'of',\n",
       " 'diving',\n",
       " 'they',\n",
       " 'find',\n",
       " 'nothing',\n",
       " 'a',\n",
       " 'few',\n",
       " 'more',\n",
       " 'days',\n",
       " 'past',\n",
       " 'and',\n",
       " 'the',\n",
       " 'two',\n",
       " 'hired',\n",
       " 'divers',\n",
       " 'found',\n",
       " 'out',\n",
       " 'that',\n",
       " 'they',\n",
       " 'a',\n",
       " 'part',\n",
       " 'of',\n",
       " 'a',\n",
       " 'major',\n",
       " 'deadly',\n",
       " 'plot',\n",
       " 'in',\n",
       " 'which',\n",
       " 'they',\n",
       " \"can't\",\n",
       " 'escape',\n",
       " 'otherwise',\n",
       " 'they',\n",
       " 'will',\n",
       " 'be',\n",
       " 'killed',\n",
       " 'they',\n",
       " 'were',\n",
       " 'hired',\n",
       " 'to',\n",
       " 'find',\n",
       " 'two',\n",
       " 'big',\n",
       " 'containers',\n",
       " 'one',\n",
       " 'contains',\n",
       " 'a',\n",
       " 'nuclear',\n",
       " 'reactor',\n",
       " 'and',\n",
       " 'the',\n",
       " 'other',\n",
       " 'contains',\n",
       " 'a',\n",
       " 'core',\n",
       " 'the',\n",
       " 'movie',\n",
       " 'also',\n",
       " 'has',\n",
       " 'a',\n",
       " 'back',\n",
       " 'story',\n",
       " 'about',\n",
       " 'another',\n",
       " 'person',\n",
       " 'brother',\n",
       " 'of',\n",
       " 'the',\n",
       " 'lead',\n",
       " 'character',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'patch',\n",
       " 'things',\n",
       " 'up',\n",
       " 'with',\n",
       " 'his',\n",
       " 'girlfriend',\n",
       " 'i',\n",
       " 'reckon',\n",
       " 'this',\n",
       " 'part',\n",
       " 'of',\n",
       " 'the',\n",
       " 'story',\n",
       " 'was',\n",
       " 'a',\n",
       " 'waste',\n",
       " 'of',\n",
       " 'time',\n",
       " 'this',\n",
       " 'also',\n",
       " 'includes',\n",
       " 'a',\n",
       " 'very',\n",
       " 'steamy',\n",
       " 'sex',\n",
       " 'scene',\n",
       " 'between',\n",
       " 'the',\n",
       " 'couple',\n",
       " 'which',\n",
       " 'to',\n",
       " 'me',\n",
       " 'is',\n",
       " 'a',\n",
       " 'complete',\n",
       " 'waste',\n",
       " 'and',\n",
       " \"wasn't\",\n",
       " 'needed',\n",
       " 'to',\n",
       " 'be',\n",
       " 'shown',\n",
       " 'however',\n",
       " 'apart',\n",
       " 'from',\n",
       " 'that',\n",
       " 'this',\n",
       " 'movie',\n",
       " 'does',\n",
       " 'have',\n",
       " 'some',\n",
       " 'good',\n",
       " 'underwater',\n",
       " 'photography',\n",
       " 'and',\n",
       " 'the',\n",
       " 'colors',\n",
       " 'blend',\n",
       " 'in',\n",
       " 'well',\n",
       " 'which',\n",
       " 'is',\n",
       " 'why',\n",
       " 'it',\n",
       " 'receives',\n",
       " '4',\n",
       " 'stars',\n",
       " 'into',\n",
       " 'the',\n",
       " 'blue',\n",
       " '2',\n",
       " 'is',\n",
       " 'a',\n",
       " 'sequel',\n",
       " 'only',\n",
       " 'by',\n",
       " 'name',\n",
       " 'none',\n",
       " 'of',\n",
       " 'the',\n",
       " 'original',\n",
       " 'actors',\n",
       " 'or',\n",
       " 'characters',\n",
       " 'return',\n",
       " 'it',\n",
       " 'has',\n",
       " 'a',\n",
       " 'dumb',\n",
       " 'plot',\n",
       " 'stupid',\n",
       " 'characters',\n",
       " 'and',\n",
       " 'a',\n",
       " 'boring',\n",
       " 'climax']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7820d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'the': 19,\n",
       "         'a': 18,\n",
       "         'of': 12,\n",
       "         'and': 9,\n",
       "         'to': 8,\n",
       "         'they': 8,\n",
       "         'is': 6,\n",
       "         'reef': 5,\n",
       "         'by': 4,\n",
       "         'day': 4,\n",
       "         'that': 4,\n",
       "         'story': 3,\n",
       "         'about': 3,\n",
       "         'two': 3,\n",
       "         'divers': 3,\n",
       "         'bottom': 3,\n",
       "         'find': 3,\n",
       "         'which': 3,\n",
       "         'this': 3,\n",
       "         'into': 2,\n",
       "         'blue': 2,\n",
       "         '2': 2,\n",
       "         'played': 2,\n",
       "         'explore': 2,\n",
       "         'hidden': 2,\n",
       "         'at': 2,\n",
       "         'one': 2,\n",
       "         'after': 2,\n",
       "         'couple': 2,\n",
       "         'hired': 2,\n",
       "         'part': 2,\n",
       "         'plot': 2,\n",
       "         'in': 2,\n",
       "         'be': 2,\n",
       "         'contains': 2,\n",
       "         'movie': 2,\n",
       "         'also': 2,\n",
       "         'has': 2,\n",
       "         'waste': 2,\n",
       "         'it': 2,\n",
       "         'characters': 2,\n",
       "         'my': 1,\n",
       "         'first': 1,\n",
       "         'review': 1,\n",
       "         '2010': 1,\n",
       "         'chris': 1,\n",
       "         'carmack': 1,\n",
       "         'laura': 1,\n",
       "         'vandervoort': 1,\n",
       "         'who': 1,\n",
       "         'love': 1,\n",
       "         'treasures': 1,\n",
       "         'local': 1,\n",
       "         'exploring': 1,\n",
       "         'are': 1,\n",
       "         'approached': 1,\n",
       "         'david': 1,\n",
       "         'anders': 1,\n",
       "         'marsha': 1,\n",
       "         'thomason': 1,\n",
       "         'tell': 1,\n",
       "         'young': 1,\n",
       "         'want': 1,\n",
       "         'hire': 1,\n",
       "         'them': 1,\n",
       "         'rare': 1,\n",
       "         'artifact': 1,\n",
       "         \"columbus'\": 1,\n",
       "         'treasure': 1,\n",
       "         'reported': 1,\n",
       "         'next': 1,\n",
       "         'four': 1,\n",
       "         'dive': 1,\n",
       "         'coarse': 1,\n",
       "         'whole': 1,\n",
       "         'diving': 1,\n",
       "         'nothing': 1,\n",
       "         'few': 1,\n",
       "         'more': 1,\n",
       "         'days': 1,\n",
       "         'past': 1,\n",
       "         'found': 1,\n",
       "         'out': 1,\n",
       "         'major': 1,\n",
       "         'deadly': 1,\n",
       "         \"can't\": 1,\n",
       "         'escape': 1,\n",
       "         'otherwise': 1,\n",
       "         'will': 1,\n",
       "         'killed': 1,\n",
       "         'were': 1,\n",
       "         'big': 1,\n",
       "         'containers': 1,\n",
       "         'nuclear': 1,\n",
       "         'reactor': 1,\n",
       "         'other': 1,\n",
       "         'core': 1,\n",
       "         'back': 1,\n",
       "         'another': 1,\n",
       "         'person': 1,\n",
       "         'brother': 1,\n",
       "         'lead': 1,\n",
       "         'character': 1,\n",
       "         'trying': 1,\n",
       "         'patch': 1,\n",
       "         'things': 1,\n",
       "         'up': 1,\n",
       "         'with': 1,\n",
       "         'his': 1,\n",
       "         'girlfriend': 1,\n",
       "         'i': 1,\n",
       "         'reckon': 1,\n",
       "         'was': 1,\n",
       "         'time': 1,\n",
       "         'includes': 1,\n",
       "         'very': 1,\n",
       "         'steamy': 1,\n",
       "         'sex': 1,\n",
       "         'scene': 1,\n",
       "         'between': 1,\n",
       "         'me': 1,\n",
       "         'complete': 1,\n",
       "         \"wasn't\": 1,\n",
       "         'needed': 1,\n",
       "         'shown': 1,\n",
       "         'however': 1,\n",
       "         'apart': 1,\n",
       "         'from': 1,\n",
       "         'does': 1,\n",
       "         'have': 1,\n",
       "         'some': 1,\n",
       "         'good': 1,\n",
       "         'underwater': 1,\n",
       "         'photography': 1,\n",
       "         'colors': 1,\n",
       "         'blend': 1,\n",
       "         'well': 1,\n",
       "         'why': 1,\n",
       "         'receives': 1,\n",
       "         '4': 1,\n",
       "         'stars': 1,\n",
       "         'sequel': 1,\n",
       "         'only': 1,\n",
       "         'name': 1,\n",
       "         'none': 1,\n",
       "         'original': 1,\n",
       "         'actors': 1,\n",
       "         'or': 1,\n",
       "         'return': 1,\n",
       "         'dumb': 1,\n",
       "         'stupid': 1,\n",
       "         'boring': 1,\n",
       "         'climax': 1})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1974cd",
   "metadata": {},
   "source": [
    "Building the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08bc6dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  80366\n"
     ]
    }
   ],
   "source": [
    "token_counts = Counter()\n",
    "\n",
    "for line, label in train_dataset:\n",
    "    tokens = tokenizer(line)\n",
    "    token_counts.update(tokens)\n",
    "print('Vocab size: ', len(token_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f24119",
   "metadata": {},
   "source": [
    "Next up, we go to mapping each unique word to a unique integer. This can be done manually using a python dictionary, where the keys are the unique tokens (words) and the value associated with each key is a unique integer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020000d9",
   "metadata": {},
   "source": [
    "Don't have the torchtext package so - implementing the vocabulary class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c097ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, ordered_dict: OrderedDict, unk_index: int=None):\n",
    "        # ordered dict maps token -> frequency (frequency is ignored after init)\n",
    "        self.itos: List[str] = list(ordered_dict.keys()) # index -> token\n",
    "        self.stoi: Dict[str,int] = {tok:idx for idx,tok in enumerate(self.itos)}\n",
    "        self.unk_index = unk_index\n",
    "        self.default_index = unk_index \n",
    "    \n",
    "    def insert_token(self, token: str, index: int) -> None:\n",
    "        \"\"\"Insert a token at a specific index (shifts existing entries)\"\"\"\n",
    "        if token in self.stoi:\n",
    "            # token already exists -> remove old entry\n",
    "            old_idx = self.stoi.pop(token)\n",
    "            # shift everything after old_idx down\n",
    "            for t, i in self.stoi.items():\n",
    "                if i > old_idx:\n",
    "                    self.stoi[t] = i-1\n",
    "            self.itos = [t for t,_ in sorted(self.stoi.items(), key=lambda x: x[1])]\n",
    "\n",
    "        # insert at the requested index\n",
    "        self.itos.insert(index, token)\n",
    "        self.stoi[token] = index\n",
    "        # shift everything >= index up by 1\n",
    "        for t,i in self.stoi.items():\n",
    "            if i >= index and t!=token:\n",
    "                self.stoi[t] = i+1\n",
    "    \n",
    "    def set_default_index(self, idx: int) -> None:\n",
    "        self.default_index = idx\n",
    "    \n",
    "    # convenience methods \n",
    "    def __getitem__(self, token:str) -> int:\n",
    "        return self.stoi.get(token, self.default_index)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.itos)\n",
    "    \n",
    "    def lookup_indices(self, tokens: List[str]) -> List[int]:\n",
    "        return [self[t] for t in tokens]\n",
    "    \n",
    "    def lookup_tokens(self, indices:List[int]) -> List[str]:\n",
    "        return [self.itos[i] for i in indices if i < len(self.itos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c65ba5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "ordered_dict =OrderedDict(sorted_by_freq_tuples)\n",
    "vocab = Vocabulary(ordered_dict)\n",
    "vocab.insert_token(\"<pad>\",0)\n",
    "vocab.insert_token(\"<unk>\",1)\n",
    "vocab.set_default_index(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4123c308",
   "metadata": {},
   "source": [
    "To demonstrate the working of the vocab object, we will convert an example input text into a list of integer values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "204a24f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 7, 32, 456]\n"
     ]
    }
   ],
   "source": [
    "print([vocab[token] for token in ['this','is','an','example']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cf33a3",
   "metadata": {},
   "source": [
    "Any token not in the vocabulary will get assigned the index 1 -  the unknown word/token index. Another reserved value is the integer 0, which serves as a placeholder, a so-called padding token, for adjusting the sequence length. We can now define the text pipeline function to transform each text accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66590497",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288498eb",
   "metadata": {},
   "source": [
    "We will generate batches of samples using DataLoader and pass the data processing pipelines declared previously to the argument collate_fn. We will wrap the text encoding into the collate_batch function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1addcc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "\n",
    "    for _text, _label in batch:\n",
    "        label_list.append(_label)\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    padded_text_list = nn.utils.rnn.pad_sequence(text_list, batch_first=True)\n",
    "    return padded_text_list, label_list, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1c9e4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a small batch\n",
    "dataloader = DataLoader(train_dataset, batch_size=4, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d207ade5",
   "metadata": {},
   "source": [
    "Let's illustrate how this padding works:\n",
    "- lets observe some of the results from the above operations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15d6785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_batch, label_batch, length_batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21c2b820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  57,   83,  721,  ...,    4,  352, 1338],\n",
      "        [   2, 1031, 4706,  ...,    0,    0,    0],\n",
      "        [  10, 3003,   11,  ...,    0,    0,    0],\n",
      "        [ 240, 1613,  420,  ...,    0,    0,    0]])\n"
     ]
    }
   ],
   "source": [
    "print(text_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd2fc01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "print(label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ee0e943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([277, 202, 253, 222])\n"
     ]
    }
   ],
   "source": [
    "print(length_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c98fdf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 277])\n"
     ]
    }
   ],
   "source": [
    "print(text_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154160b2",
   "metadata": {},
   "source": [
    "Finally, let us divide all 3 datasets into data loaders with a batch size of 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "decc1319",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac777fe",
   "metadata": {},
   "source": [
    "Now, the data is in a suitable format for an rnn model, which is implemented belowL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5681c0d",
   "metadata": {},
   "source": [
    "**Embedding layers for sentence encoding:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fe440d",
   "metadata": {},
   "source": [
    "Given a set of tokens of size n+2 (n is the size of the token set, plus index 0 is reserved for the padding placeholder, and 1 is for the words not present in the token set), an embedding matrix of size (n+2)xembedding_dim will be created where each row of this matrix represents numeric features associated with a token. Therefore, when an integer index, i, is given as input to the embedding, it will lookup the corresponding row of the matrix at index i and return numeric features. The embedding matrix serves as the input to our NN models, In practice creating an embedding layer is simply done using nn.Embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5dcd7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(\n",
    "    num_embeddings=10,\n",
    "    embedding_dim=3,\n",
    "    padding_idx=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d436e54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 3.5943e-01,  1.6515e-01, -1.1147e+00],\n",
      "         [ 8.9677e-01,  9.6746e-01,  1.1298e+00],\n",
      "         [ 7.7055e-04, -2.0528e+00, -7.1877e-01],\n",
      "         [ 1.6979e+00, -2.8334e-01,  2.3272e-01]],\n",
      "\n",
      "        [[ 7.7055e-04, -2.0528e+00, -7.1877e-01],\n",
      "         [-1.9676e+00,  2.5564e-01,  2.4446e-01],\n",
      "         [ 8.9677e-01,  9.6746e-01,  1.1298e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# a batch of 2 samples of 4 indices each\n",
    "text_encoded_input = torch.LongTensor([[1,2,4,5],[4,3,2,0]])\n",
    "print(embedding(text_encoded_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883b9a13",
   "metadata": {},
   "source": [
    "- Inputs to the embedding layer must have a rank of 2 - with the dimensionality of batch_size x input_length, where input_length is the length of sequences (here, 4). Output of the embedding layer will then have output of size: batchsize x inputlength x embedding_dim. Where embedding_dim is the size of the embedding features. The other argument provided to the embedding_layer, num_embeddings, correspinds to the unique integer values that the model will receive as input (for instance, n+2, set to 10 in this example). Therefore the embedding matrix in this case has the size 10x3.\n",
    "- padding_idx indicates the token index for padding (here, 0), which, if specified, will not contribute to the gradient updates during training. In our example, the length of the original sequence of the second example is 3, which we padded with 1 more element 0. The embedding output of the padded element is [0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad46db4",
   "metadata": {},
   "source": [
    "**Building an RNN model:**\n",
    "- Now, we can build an RNN model. Using the nn.Module class, we can combine the embedding layer, the recurrent layers of the RNN,  and the fully connected non-recurrent layers. For the recurrent layers, we can use any of the following implementations:\n",
    "  - RNN: a regular RNN layer, that is, a fully connected recurrent layer\n",
    "  - LSTM:  a long short-term memory RNN, which is useful for capturing long-term dependencies\n",
    "  - GRU: a recurrent layer with a gated recurrent unit. \n",
    "- To see how a multilayer RNN model can be built using one of these recurrent layers, in the following example, we create an RNN model with 2 recurrent layers of type RNN. Finally, we will add a non-recurrent fully connected layer as the output layer, which will return a single output value as the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "764ebd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(64, 32, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, hidden = self.rnn(x)\n",
    "        out = hidden[-1,:,:] # we use the final hidden state from the last hidden layer as the input to the fc layer, as this is equal to the output of rnn's last time step\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = RNN(64, 32)\n",
    "print(model)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cfd3962",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48bf0947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to(device)\n",
    "# model(torch.randn(5, 3, 64).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172dc42c",
   "metadata": {},
   "source": [
    "Building RNNs with these recurrent layers is as straightforward as can be seen above. In the next subsection, we go back to the sentiment analysis task and build an RNN model to solve that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9368140",
   "metadata": {},
   "source": [
    "**Building an RNN model for the sentiment analysis task:**\n",
    "- Because of the length of the sequences we've got and the need to store and propagate early learned useful context over long sequences we are going to use an LSTM layer to account for this (long range effects). We create an RNN model for sentiment analysis, starting with an embedding layer producing word embeddings of feature size 20 (embed_dim=20). Then, a recurrent layer of type LSTM eill be added. Finally, we add a fully connected layer as a hidden layer and another fully connected layer as the output layer, which will return a single class-membership probability value using the logistic sigmoid activation as the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f8086da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, batch_first=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        out = nn.utils.rnn.pack_padded_sequence(\n",
    "            out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True\n",
    "        )\n",
    "        out, (hidden, cell) = self.rnn(out)\n",
    "        out = hidden[-1, :, :]\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d624b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11d3edeb0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "embed_dim = 20\n",
    "rnn_hidden_size = 64\n",
    "fc_hidden_size = 64\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af38b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "deb858a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(80368, 20, padding_idx=0)\n",
       "  (rnn): LSTM(20, 64, batch_first=True)\n",
       "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "239610d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    for text_batch, label_batch, lengths in dataloader:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        label_batch = label_batch.float()\n",
    "        text_batch, label_batch = text_batch.to(device), label_batch.to(device)\n",
    "        pred = model(text_batch, lengths)[:,0]\n",
    "        loss = loss_fn(pred, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += (\n",
    "            (pred >= 0.5).float() == label_batch\n",
    "        ).float().sum().item()\n",
    "        total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4d40348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch, lengths in dataloader:\n",
    "            label_batch = label_batch.float()\n",
    "            text_batch, label_batch = text_batch.to(device), label_batch.to(device)\n",
    "            pred = model(text_batch, lengths)[:,0]\n",
    "            loss = loss_fn(pred, label_batch)\n",
    "            total_acc += (\n",
    "                (pred >= 0.5).float() == label_batch\n",
    "            ).float().sum().item()\n",
    "            total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "95341339",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "20af7576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | accuracy: 0.5581 | val_accuracy: 0.6226\n",
      "Epoch: 1 | accuracy: 0.6668 | val_accuracy: 0.7200\n",
      "Epoch: 2 | accuracy: 0.6828 | val_accuracy: 0.7420\n",
      "Epoch: 3 | accuracy: 0.7689 | val_accuracy: 0.7678\n",
      "Epoch: 4 | accuracy: 0.8109 | val_accuracy: 0.7712\n",
      "Epoch: 5 | accuracy: 0.8307 | val_accuracy: 0.7962\n",
      "Epoch: 6 | accuracy: 0.8565 | val_accuracy: 0.7898\n",
      "Epoch: 7 | accuracy: 0.8801 | val_accuracy: 0.8342\n",
      "Epoch: 8 | accuracy: 0.8858 | val_accuracy: 0.8272\n",
      "Epoch: 9 | accuracy: 0.8940 | val_accuracy: 0.8336\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "torch.manual_seed(1)\n",
    "for epoch in range(num_epochs):\n",
    "    acc_train, loss_train = train(train_dl)\n",
    "    acc_valid, loss_valid = evaluate(valid_dl)\n",
    "    print(f'Epoch: {epoch} | accuracy: {acc_train:.4f} | val_accuracy: {acc_valid:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ed484b",
   "metadata": {},
   "source": [
    "Evaluate on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "65169571",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test, _ = evaluate(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f62a16bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.8302\n"
     ]
    }
   ],
   "source": [
    "print(f'test accuracy: {acc_test:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60acfb62",
   "metadata": {},
   "source": [
    "**More on the bidirectional RNN:**\n",
    "- In addition, we will set the bidirectional configuration of the LSTM to true, which will make the recurrent layer pass through input sequences from both directions, start to end, as well as in the reverse direction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9f01a620",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size, embed_dim, padding_idx=0\n",
    "        )\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size*2, fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
    "        _, (hidden,cell) = self.rnn(out)\n",
    "        out = torch.cat((hidden[-2,:,:], hidden[-1, :, :]), dim=1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d5e17ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d4a9adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a596b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | accuracy: 0.5036 | val_accuracy: 0.4856\n",
      "Epoch: 1 | accuracy: 0.5036 | val_accuracy: 0.4856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_h/yzv4_kzj2yv3z5xh7lks3hpr0000gn/T/ipykernel_9387/2878062256.py:3: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
      "/var/folders/_h/yzv4_kzj2yv3z5xh7lks3hpr0000gn/T/ipykernel_9387/2878062256.py:4: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  text = re.sub(\"[^\\w']+\",' ', text.lower()) + ' ' +' '.join(emoticons).replace('-','')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m torch.manual_seed(\u001b[32m1\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     acc_train, loss_train = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     acc_valid, loss_valid = evaluate(valid_dl)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_train\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | val_accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_valid\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(dataloader)\u001b[39m\n\u001b[32m      2\u001b[39m model.train()\n\u001b[32m      3\u001b[39m total_acc, total_loss = \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mset_to_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_batch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_batch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ML/Machine-Learning-and-Big-Data-Analytics/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ML/Machine-Learning-and-Big-Data-Analytics/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ML/Machine-Learning-and-Big-Data-Analytics/venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mcollate_batch\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _text, _label \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[32m      5\u001b[39m     label_list.append(_label)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     processed_text = torch.tensor(\u001b[43mtext_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_text\u001b[49m\u001b[43m)\u001b[49m, dtype=torch.int64)\n\u001b[32m      7\u001b[39m     text_list.append(processed_text)\n\u001b[32m      8\u001b[39m     lengths.append(processed_text.size(\u001b[32m0\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m text_pipeline = \u001b[38;5;28;01mlambda\u001b[39;00m x: [vocab[token] \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mtokenizer\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m      2\u001b[39m text = re.sub(\u001b[33m'\u001b[39m\u001b[33m<[^>]*>\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, text)\n\u001b[32m      3\u001b[39m emoticons = re.findall(\u001b[33m'\u001b[39m\u001b[33m(?::|;|=)(?:-)?(?:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m)|\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m(|D|P)\u001b[39m\u001b[33m'\u001b[39m, text.lower())\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m text = re.sub(\u001b[33m\"\u001b[39m\u001b[33m[^\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]+\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m, text.lower()) + \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m +\u001b[33;43m'\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43memoticons\u001b[49m\u001b[43m)\u001b[49m.replace(\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m tokenized = text.split()\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tokenized\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "torch.manual_seed(1)\n",
    "for epoch in range(num_epochs):\n",
    "    acc_train, loss_train = train(train_dl)\n",
    "    acc_valid, loss_valid = evaluate(valid_dl)\n",
    "    print(f'Epoch: {epoch} | accuracy: {acc_train:.4f} | val_accuracy: {acc_valid:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85f8009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
