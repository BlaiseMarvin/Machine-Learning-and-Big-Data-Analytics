{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9e61b91",
   "metadata": {},
   "source": [
    "Using 1D Convolutional layers to process sequences:\n",
    "- 1D Conv layers can slide several kernels across a sequence, producing a 1D feature map per kernel. Each kernel learns to detect a very short squential pattern (no longer than the kernel size). Using 10 kernels results in layer's output composed of 10 1D sequences (all of the same length). This means you can build a neural network composed of a mix of recurrent layers and 1D conv layers . \n",
    "- Below, a model is built starting with a 1D conv layer that downsamples the input sequence by a factor of 2, using a stride of 2. The kernel size is larger than the stride so all inputs will be used to compute the layer's output, and therefore the model can learn to preserve the useful information, dropping only the unimportant details. By shortening the sequences the conv layer may help the rnn detect longer patterns, so we can afford to double the input sequence to 112 days\n",
    "- Note: We must also crop off the first 3 timesteps in the targets: indeed the kernel's size is 4, so the first output of the conv layer is based off the input timesteps (0 to 3), and the first forecasts wull be for timesteps 4 to 17 (instead of 1 to 14). Moreover, we must downsample the targets by a factor of 2 because of the stride:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eac32e",
   "metadata": {},
   "source": [
    "Building this model out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fcab47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.fetch_data import fetch_timeseries_data\n",
    "from utils.early_stopping import EarlyStopping\n",
    "from utils.fetch_data import create_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c090c081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x161147cd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0e5595",
   "metadata": {},
   "source": [
    "Get the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "799fe8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_type</th>\n",
       "      <th>bus</th>\n",
       "      <th>rail</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>U</td>\n",
       "      <td>297192</td>\n",
       "      <td>126455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-02</th>\n",
       "      <td>W</td>\n",
       "      <td>780827</td>\n",
       "      <td>501952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-03</th>\n",
       "      <td>W</td>\n",
       "      <td>824923</td>\n",
       "      <td>536432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-04</th>\n",
       "      <td>W</td>\n",
       "      <td>870021</td>\n",
       "      <td>550011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-05</th>\n",
       "      <td>W</td>\n",
       "      <td>890426</td>\n",
       "      <td>557917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           day_type     bus    rail\n",
       "date                               \n",
       "2001-01-01        U  297192  126455\n",
       "2001-01-02        W  780827  501952\n",
       "2001-01-03        W  824923  536432\n",
       "2001-01-04        W  870021  550011\n",
       "2001-01-05        W  890426  557917"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = fetch_timeseries_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f74e71f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9009, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d2dd24",
   "metadata": {},
   "source": [
    "Already explored this in notebook 13 and 14 - so proceed now to fetch the train, validation, and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bde60d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "rail_train, rail_valid, rail_test = create_splits(df, attr='rail', train_ran=['2014-01','2023-12'],val_ran=['2024-01','2024-12'],test_ran=['2025-01'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db451752",
   "metadata": {},
   "source": [
    "Creating chunks now - considering the fact that the first layer will be a 1D Conv layer, with a kernel size of 4 and stride of 2. Meaning right off the based off the nature of the kernel size, we aren't processing a single item in a sequence at a time but rather 4 items at a time and hence the targets need to start after skipping the first 4 items. Also, because of the stride of 2 - the targets need to get offset by 2 (skipping 1 before taking the next target batch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "795b0d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 112\n",
    "forecasting_horizon = 14\n",
    "strides = 2\n",
    "kernel_size=4\n",
    "\n",
    "def create_x_chunks(ds):\n",
    "    return [ds[i:i+seq_length] for i in range(len(ds)-seq_length-forecasting_horizon-strides+1)]\n",
    "\n",
    "# def create_y_chunks(ds):\n",
    "#     y_chunks = []\n",
    "#     for i in range(len(ds)-seq_length-forecasting_horizon-strides+1):\n",
    "#         seq_chunk = [ds[i+j+4:i+j+4+forecasting_horizon] for j in range(0, seq_length, 2)] #step of 2 for the range because of the strides, skip 1 then get next 14\n",
    "#         y_chunks.append(seq_chunk)\n",
    "#     return y_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "28c539e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_y_chunks2(ds):\n",
    "    y_chunks = []\n",
    "    conv_seq_len = (seq_length - kernel_size) // 2 + 1   # 55\n",
    "\n",
    "    for i in range(len(ds)-seq_length-forecasting_horizon-strides+1):\n",
    "        seq_chunk = []\n",
    "        for j in range(conv_seq_len):\n",
    "            start = i + j*strides + kernel_size\n",
    "            end   = start + forecasting_horizon\n",
    "            seq_chunk.append(ds[start:end])\n",
    "        y_chunks.append(seq_chunk)\n",
    "\n",
    "    return y_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7af8c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_chunks, train_y_chunks = create_x_chunks(rail_train.values.tolist()), create_y_chunks2(rail_train.values.tolist())\n",
    "valid_x_chunks, valid_y_chunks = create_x_chunks(rail_valid.values.tolist()), create_y_chunks2(rail_valid.values.tolist())\n",
    "test_x_chunks, test_y_chunks = create_x_chunks(rail_test.values.tolist()), create_y_chunks2(rail_test.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b542986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_chunks, train_y_chunks = torch.tensor(train_x_chunks), torch.tensor(train_y_chunks)\n",
    "valid_x_chunks, valid_y_chunks = torch.tensor(valid_x_chunks), torch.tensor(valid_y_chunks)\n",
    "test_x_chunks, test_y_chunks = torch.tensor(test_x_chunks), torch.tensor(test_y_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5ebeed5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3525, 112]), torch.Size([3525, 55, 14]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_chunks.shape, train_y_chunks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "71c8e56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([239, 112]), torch.Size([239, 55, 14]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_x_chunks.shape, valid_y_chunks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5065e646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([116, 112]), torch.Size([116, 55, 14]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_chunks.shape, test_y_chunks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabdcd1e",
   "metadata": {},
   "source": [
    "Build the datasets using the chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d0ffbfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TsDataset(Dataset):\n",
    "    def __init__(self, x_chunk, y_chunk):\n",
    "        super().__init__()\n",
    "        self.x_chunk = x_chunk.unsqueeze(2)\n",
    "        self.y_chunk = y_chunk\n",
    "    def __len__(self):\n",
    "        return self.x_chunk.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        x , y = self.x_chunk[index,:,:], self.y_chunk[index,:,:]\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a0f31018",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TsDataset(train_x_chunks, train_y_chunks)\n",
    "val_ds = TsDataset(valid_x_chunks, valid_y_chunks)\n",
    "test_ds = TsDataset(test_x_chunks, test_y_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29167f2e",
   "metadata": {},
   "source": [
    "Build the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccea3c6",
   "metadata": {},
   "source": [
    "Going to use my custom LSTM cell with Layer Normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "43567a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, device):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(input_size, 4*hidden_size,device=device) # instead of breaking this down, could just compute these with one linear layer and break down its results later\n",
    "        nn.init.xavier_uniform_(self.input.weight.data)\n",
    "        self.hidden = nn.Linear(hidden_size, 4*hidden_size,device=device) # same for this\n",
    "        nn.init.xavier_uniform_(self.hidden.weight.data)\n",
    "        nn.init.zeros_(self.input.bias)\n",
    "        nn.init.zeros_(self.hidden.bias)\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.ln_gates = nn.LayerNorm(4*hidden_size,device=device)\n",
    "        self.ln_c = nn.LayerNorm(hidden_size, device=device)\n",
    "        self.device = device\n",
    "    def forward(self, x, prev_h, prev_c):\n",
    "        computed_inputs = self.input(x)\n",
    "        computed_hiddens = self.hidden(prev_h)\n",
    "\n",
    "        gates = self.ln_gates(computed_inputs+computed_hiddens)\n",
    "\n",
    "        # compute the input gate\n",
    "        input_gate = torch.sigmoid(gates[:,:self.hidden_size])\n",
    "        forget_gate = torch.sigmoid(gates[:,self.hidden_size:2*self.hidden_size])\n",
    "        signal = torch.tanh(gates[:,2*self.hidden_size:3*self.hidden_size])\n",
    "        output_gate = torch.sigmoid(gates[:,3*self.hidden_size:4*self.hidden_size])\n",
    "        long_state = forget_gate*prev_c + input_gate*signal\n",
    "        return output_gate*torch.tanh(self.ln_c(long_state)), long_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "539bb8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLSTMLayer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, device):\n",
    "        super().__init__()\n",
    "        self.lstm_cell = CustomLSTMCell(input_size, hidden_size,device)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "    def forward(self, input):\n",
    "        batch, seq_len, _ = input.shape\n",
    "        short_term_state = []\n",
    "        long_term_state = []\n",
    "        prev_h = torch.zeros((batch, self.hidden_size), device=self.device)\n",
    "        prev_c = torch.zeros((batch, self.hidden_size), device= self.device)\n",
    "\n",
    "        for i in range(seq_len):\n",
    "            xt = input[:,i,:]\n",
    "            prev_h, prev_c = self.lstm_cell(xt, prev_h, prev_c)\n",
    "            short_term_state.append(prev_h)\n",
    "            long_term_state.append(prev_c)\n",
    "        out = torch.stack(short_term_state, dim=1)\n",
    "        return out, (prev_h,  prev_c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4c25906b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x161147cd0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c1509cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, input_size, kernels, hidden_size, device):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(input_size, kernels, kernel_size=4, stride=2, device=device)\n",
    "        self.lstm = CustomLSTMLayer(kernels, hidden_size, device=device)\n",
    "        self.linear = nn.Linear(hidden_size, 14, device=device)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # input is of shape: batch size, seq_len, features\n",
    "        # conv1d expects an input of batch_size, channels, seq_length \n",
    "        x = x.permute(0, 2, 1)\n",
    "        out = self.conv(x)\n",
    "        # output is now of shape batch_size, channels, seq_length (with the length now reduced to 55 after the convolution operation)\n",
    "        # switching back to what the lstm expects\n",
    "        out = out.permute(0, 2, 1)\n",
    "\n",
    "        out, (_,_) = self.lstm(out)\n",
    "\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6b791401",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5ac5bf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvLSTM(1, 32, 32, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1e9ca66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "criterion = nn.HuberLoss(reduction='sum')\n",
    "early_stopper = EarlyStopping(patience=50, checkpoint_path='convlstm.pt', restore_best_weights=True, verbose=True)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',patience=5, factor=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f842d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_loss = [0] * n_epochs\n",
    "val_loss = [0] * n_epochs\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    # iterate through the training data\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x_batch)\n",
    "        # adding l1 norm\n",
    "        norm = sum(p.abs().sum() for p in model.parameters())\n",
    "        loss = criterion(out, y_batch) + 1e-5*norm\n",
    "        loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), 2.0)\n",
    "        optimizer.step()\n",
    "        train_loss[epoch]+=loss.item()\n",
    "    train_loss[epoch] /= len(train_dl.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_batch,y_batch in val_dl:\n",
    "            x_batch,y_batch = x_batch.to(device),y_batch.to(device)\n",
    "            out = model(x_batch)\n",
    "            loss = criterion(out, y_batch)\n",
    "            val_loss[epoch] += loss.item()\n",
    "        val_loss[epoch] /= len(val_dl.dataset)\n",
    "\n",
    "        scheduler.step(val_loss[epoch])\n",
    "        print(f'Epoch: {epoch+1}| Train loss: {train_loss[epoch]:.4f}| Val loss: {val_loss[epoch]:.4f}')\n",
    "        early_stopper(val_loss[epoch], model, optimizer, epoch)\n",
    "        if early_stopper.should_stop:\n",
    "            print(f\"Stopping at epoch: {epoch+1}\")\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
