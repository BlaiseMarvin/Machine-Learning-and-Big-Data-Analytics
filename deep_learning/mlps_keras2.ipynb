{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53fd700d",
   "metadata": {},
   "source": [
    "**Building complex models using the functional API:**\n",
    "- One example of a non_sequential neurela net is a wide and deep neural net. introduced ina 2016 paper\n",
    "- learns both deep patterns - by forcing data through a deep net and simple rules - through using a shallow approach\n",
    "- we now build such a neural net and use it to tackle the california housing problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "255fd2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "004ef183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96235460",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(r\"C:\\Users\\blais\\Documents\\ML\\deep_learning\\housing_x.csv\")\n",
    "Y = pd.read_csv(r\"C:\\Users\\blais\\Documents\\ML\\deep_learning\\housing_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f944920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.iloc[:, 1:]\n",
    "Y = Y.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ed434b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2)\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(X_train, y_train, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75a30266",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "y_train_scaled = scaler.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94f82aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_scaled, y_test_scaled = scaler.transform(y_valid), scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf4e6671",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = X_train.values, X_valid.values, y_train_scaled.reshape(y_train_scaled.shape[0],), y_valid_scaled.reshape(y_valid_scaled.shape[0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1706f451",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = X_test.values, y_test_scaled.reshape(y_test_scaled.shape[0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f774a8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66ac33f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60990201",
   "metadata": {},
   "source": [
    "Get the data in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85647dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a wide and deep neural net\n",
    "\n",
    "normalization_layer = tf.keras.layers.Normalization()\n",
    "hidden_layer1 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "hidden_layer2 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "concat_layer = tf.keras.layers.Concatenate()\n",
    "output_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "input_ = tf.keras.layers.Input(shape = X_train.shape[1:])\n",
    "normalized = normalization_layer(input_)\n",
    "hidden1 = hidden_layer1(normalized)\n",
    "hidden2 = hidden_layer2(hidden1)\n",
    "concat = concat_layer([normalized, hidden2])\n",
    "output = output_layer(concat)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98d76a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">750</span> │ normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        │         \u001b[38;5;34m49\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mNormalization\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │        \u001b[38;5;34m750\u001b[0m │ normalization[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │        \u001b[38;5;34m930\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ normalization[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m55\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,784</span> (6.97 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,784\u001b[0m (6.97 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,735</span> (6.78 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,735\u001b[0m (6.78 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49</span> (200.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m49\u001b[0m (200.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8da7ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 1.0e-3)\n",
    "\n",
    "model.compile(loss = \"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "\n",
    "normalization_layer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bed69965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - RootMeanSquaredError: 1.0456 - loss: 1.1225 - val_RootMeanSquaredError: 0.5206 - val_loss: 0.2710\n",
      "Epoch 2/20\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5921 - loss: 0.3508 - val_RootMeanSquaredError: 0.4763 - val_loss: 0.2269\n",
      "Epoch 3/20\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5240 - loss: 0.2748 - val_RootMeanSquaredError: 0.4621 - val_loss: 0.2136\n",
      "Epoch 4/20\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5010 - loss: 0.2512 - val_RootMeanSquaredError: 0.4558 - val_loss: 0.2078\n",
      "Epoch 5/20\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4901 - loss: 0.2403 - val_RootMeanSquaredError: 0.4519 - val_loss: 0.2042\n",
      "Epoch 6/20\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4823 - loss: 0.2328 - val_RootMeanSquaredError: 0.4489 - val_loss: 0.2015\n",
      "Epoch 7/20\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4765 - loss: 0.2272 - val_RootMeanSquaredError: 0.4454 - val_loss: 0.1984\n",
      "Epoch 8/20\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4716 - loss: 0.2225 - val_RootMeanSquaredError: 0.4425 - val_loss: 0.1958\n",
      "Epoch 9/20\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4673 - loss: 0.2185 - val_RootMeanSquaredError: 0.4397 - val_loss: 0.1933\n",
      "Epoch 10/20\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4638 - loss: 0.2152 - val_RootMeanSquaredError: 0.4373 - val_loss: 0.1912\n",
      "Epoch 11/20\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4617 - loss: 0.2132 - val_RootMeanSquaredError: 0.4357 - val_loss: 0.1899\n",
      "Epoch 12/20\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4660 - loss: 0.2172 - val_RootMeanSquaredError: 0.4340 - val_loss: 0.1884\n",
      "Epoch 13/20\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4627 - loss: 0.2141 - val_RootMeanSquaredError: 0.4338 - val_loss: 0.1882\n",
      "Epoch 14/20\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4584 - loss: 0.2102 - val_RootMeanSquaredError: 0.4304 - val_loss: 0.1852\n",
      "Epoch 15/20\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4519 - loss: 0.2042 - val_RootMeanSquaredError: 0.4302 - val_loss: 0.1851\n",
      "Epoch 16/20\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4487 - loss: 0.2014 - val_RootMeanSquaredError: 0.4289 - val_loss: 0.1839\n",
      "Epoch 17/20\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4462 - loss: 0.1991 - val_RootMeanSquaredError: 0.4284 - val_loss: 0.1835\n",
      "Epoch 18/20\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4445 - loss: 0.1976 - val_RootMeanSquaredError: 0.4269 - val_loss: 0.1822\n",
      "Epoch 19/20\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4439 - loss: 0.1971 - val_RootMeanSquaredError: 0.4278 - val_loss: 0.1830\n",
      "Epoch 20/20\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4439 - loss: 0.1971 - val_RootMeanSquaredError: 0.4258 - val_loss: 0.1813\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_scaled, epochs=20, validation_data = (X_valid, y_valid_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a2320b",
   "metadata": {},
   "source": [
    "But - what if you want to send a subset of features through the wide path and a different subset (possibly overlapping through the deep path). In this case - one solution is to use multiple inputs. - For example, suppose we want to send 5 features through the wide path and 6 features through the deep path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81b98b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11888, 24)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2419a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wide = tf.keras.layers.Input(shape=[13]) # features 0 to 12 \n",
    "input_deep = tf.keras.layers.Input(shape=[22]) # features 2 to 23\n",
    "norm_layer_deep = tf.keras.layers.Normalization()\n",
    "norm_layer_wide = tf.keras.layers.Normalization()\n",
    "\n",
    "norm_wide = norm_layer_wide(input_wide)\n",
    "norm_deep = norm_layer_deep(input_deep)\n",
    "\n",
    "hidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(norm_deep)\n",
    "hidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "output = tf.keras.layers.Dense(1)(concat)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_wide, input_deep], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "921a1116",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1.0e-3)\n",
    "model.compile(loss=\"mse\",optimizer=optimizer,metrics=[\"RootMeanSquaredError\"])\n",
    "\n",
    "X_train_wide, X_train_deep = X_train[:,:13], X_train[:,2:]\n",
    "X_valid_wide, X_valid_deep = X_valid[:,:13], X_valid[:,2:]\n",
    "X_test_wide, X_test_deep = X_test[:,:13], X_test[:,2:]\n",
    "X_new_wide, X_new_deep = X_test_wide[:3], X_test_deep[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d68c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_layer_wide.adapt(X_train_wide)\n",
    "norm_layer_deep.adapt(X_train_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fff7f7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.8715 - loss: 0.7883 - val_RootMeanSquaredError: 0.5024 - val_loss: 0.2524\n",
      "Epoch 2/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5531 - loss: 0.3062 - val_RootMeanSquaredError: 0.4702 - val_loss: 0.2211\n",
      "Epoch 3/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5209 - loss: 0.2715 - val_RootMeanSquaredError: 0.4603 - val_loss: 0.2118\n",
      "Epoch 4/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5062 - loss: 0.2564 - val_RootMeanSquaredError: 0.4502 - val_loss: 0.2026\n",
      "Epoch 5/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5030 - loss: 0.2531 - val_RootMeanSquaredError: 0.4520 - val_loss: 0.2043\n",
      "Epoch 6/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4982 - loss: 0.2483 - val_RootMeanSquaredError: 0.4448 - val_loss: 0.1978\n",
      "Epoch 7/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4894 - loss: 0.2396 - val_RootMeanSquaredError: 0.4457 - val_loss: 0.1986\n",
      "Epoch 8/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4817 - loss: 0.2321 - val_RootMeanSquaredError: 0.4403 - val_loss: 0.1938\n",
      "Epoch 9/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4758 - loss: 0.2265 - val_RootMeanSquaredError: 0.4403 - val_loss: 0.1939\n",
      "Epoch 10/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4726 - loss: 0.2235 - val_RootMeanSquaredError: 0.4373 - val_loss: 0.1912\n",
      "Epoch 11/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4699 - loss: 0.2209 - val_RootMeanSquaredError: 0.4377 - val_loss: 0.1916\n",
      "Epoch 12/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4685 - loss: 0.2196 - val_RootMeanSquaredError: 0.4345 - val_loss: 0.1888\n",
      "Epoch 13/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4701 - loss: 0.2211 - val_RootMeanSquaredError: 0.4368 - val_loss: 0.1908\n",
      "Epoch 14/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4681 - loss: 0.2192 - val_RootMeanSquaredError: 0.4320 - val_loss: 0.1866\n",
      "Epoch 15/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4645 - loss: 0.2158 - val_RootMeanSquaredError: 0.4331 - val_loss: 0.1876\n",
      "Epoch 16/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4603 - loss: 0.2120 - val_RootMeanSquaredError: 0.4314 - val_loss: 0.1861\n",
      "Epoch 17/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4572 - loss: 0.2090 - val_RootMeanSquaredError: 0.4309 - val_loss: 0.1857\n",
      "Epoch 18/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4553 - loss: 0.2074 - val_RootMeanSquaredError: 0.4300 - val_loss: 0.1849\n",
      "Epoch 19/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4536 - loss: 0.2058 - val_RootMeanSquaredError: 0.4301 - val_loss: 0.1850\n",
      "Epoch 20/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4545 - loss: 0.2066 - val_RootMeanSquaredError: 0.4294 - val_loss: 0.1844\n",
      "Epoch 21/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4549 - loss: 0.2070 - val_RootMeanSquaredError: 0.4299 - val_loss: 0.1848\n",
      "Epoch 22/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4532 - loss: 0.2055 - val_RootMeanSquaredError: 0.4285 - val_loss: 0.1836\n",
      "Epoch 23/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4510 - loss: 0.2035 - val_RootMeanSquaredError: 0.4294 - val_loss: 0.1844\n",
      "Epoch 24/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4495 - loss: 0.2021 - val_RootMeanSquaredError: 0.4272 - val_loss: 0.1825\n",
      "Epoch 25/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4466 - loss: 0.1995 - val_RootMeanSquaredError: 0.4268 - val_loss: 0.1822\n",
      "Epoch 26/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4458 - loss: 0.1988 - val_RootMeanSquaredError: 0.4260 - val_loss: 0.1815\n",
      "Epoch 27/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4445 - loss: 0.1976 - val_RootMeanSquaredError: 0.4263 - val_loss: 0.1817\n",
      "Epoch 28/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4447 - loss: 0.1978 - val_RootMeanSquaredError: 0.4257 - val_loss: 0.1812\n",
      "Epoch 29/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4439 - loss: 0.1971 - val_RootMeanSquaredError: 0.4261 - val_loss: 0.1816\n",
      "Epoch 30/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4437 - loss: 0.1969 - val_RootMeanSquaredError: 0.4250 - val_loss: 0.1806\n",
      "Epoch 31/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4425 - loss: 0.1959 - val_RootMeanSquaredError: 0.4257 - val_loss: 0.1812\n",
      "Epoch 32/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4416 - loss: 0.1951 - val_RootMeanSquaredError: 0.4244 - val_loss: 0.1801\n",
      "Epoch 33/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4398 - loss: 0.1935 - val_RootMeanSquaredError: 0.4247 - val_loss: 0.1804\n",
      "Epoch 34/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4394 - loss: 0.1932 - val_RootMeanSquaredError: 0.4241 - val_loss: 0.1799\n",
      "Epoch 35/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.4378 - loss: 0.1917 - val_RootMeanSquaredError: 0.4238 - val_loss: 0.1796\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((X_train_wide, X_train_deep), y_train_scaled, epochs=35,\n",
    "                    validation_data = ((X_valid_wide, X_valid_deep), y_valid_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5256e0eb",
   "metadata": {},
   "source": [
    "Instead of passing a tuple (X_train_wide, X_train_deep), you can pass a dictionary {\"input_wide\": X_train_wide, \"input_deep\": X_train_deep}, if you set the name input_wide and input_deep when creating the inputs. Highly recommended when there are many inputs to clarify the code and avoid getting the wrong order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d11edb5",
   "metadata": {},
   "source": [
    "There also are many use cases in which you may want to have multiple outputs:\n",
    "- Adding an extra output is quite easy - we just connect it to the appropriate layer and add it to the model's list of outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba69ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a network with 2 inputs and 2 outputs\n",
    "\n",
    "input_wide = tf.keras.layers.Input(shape=[13])\n",
    "input_deep = tf.keras.layers.Input(shape=[22])\n",
    "\n",
    "normalization_wide = tf.keras.layers.Normalization()\n",
    "normalization_deep = tf.keras.layers.Normalization()\n",
    "\n",
    "norm_wide = normalization_wide(input_wide)\n",
    "\n",
    "norm_deep = normalization_deep(input_deep)\n",
    "hidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(norm_deep)\n",
    "hidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "\n",
    "concat = tf.keras.layers.concatenate([norm_wide,hidden2])\n",
    "\n",
    "output = tf.keras.layers.Dense(1, name=\"main_out\")(concat)\n",
    "\n",
    "aux_output = tf.keras.layers.Dense(1, name=\"aux_out\")(hidden2)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_wide, input_deep], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e70784",
   "metadata": {},
   "source": [
    "Each output will need its own loss function.\n",
    "Therefore - when compiling the model - pass a list of losses. \n",
    "Passing a single loss means it should be applied for all outputs. By default, keras will compute all losses and add them to get the final loss used for training. Since we care much more about main output than auxiliary output - we want to give the main output's loss a much greater weight. It is possoible to set all the loss weights when compiling the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd7fdaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1.0e-3)\n",
    "model.compile(loss=(\"mse\",\"mse\"), loss_weights=(0.9, 0.1), optimizer=optimizer, metrics=[\"RootMeanSquaredError\",\"RootMeanSquaredError\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862e6565",
   "metadata": {},
   "source": [
    "Now, when training - need to provide labels for all outputs - In this example - the main output and the aux output should predict the same thing and we've simply added the aux for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b57410ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_wide.adapt(X_train_wide)\n",
    "normalization_deep.adapt(X_train_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b014d3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - aux_out_RootMeanSquaredError: 0.8988 - aux_out_loss: 0.8147 - loss: 0.9319 - main_out_RootMeanSquaredError: 0.9600 - main_out_loss: 0.9449 - val_aux_out_RootMeanSquaredError: 0.5352 - val_aux_out_loss: 0.2846 - val_loss: 0.2853 - val_main_out_RootMeanSquaredError: 0.5340 - val_main_out_loss: 0.2825\n",
      "Epoch 2/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_out_RootMeanSquaredError: 0.6088 - aux_out_loss: 0.3709 - loss: 0.3715 - main_out_RootMeanSquaredError: 0.6087 - main_out_loss: 0.3716 - val_aux_out_RootMeanSquaredError: 0.5005 - val_aux_out_loss: 0.2486 - val_loss: 0.2425 - val_main_out_RootMeanSquaredError: 0.4915 - val_main_out_loss: 0.2399\n",
      "Epoch 3/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_out_RootMeanSquaredError: 0.5609 - aux_out_loss: 0.3147 - loss: 0.3175 - main_out_RootMeanSquaredError: 0.5631 - main_out_loss: 0.3178 - val_aux_out_RootMeanSquaredError: 0.4831 - val_aux_out_loss: 0.2323 - val_loss: 0.2285 - val_main_out_RootMeanSquaredError: 0.4774 - val_main_out_loss: 0.2269\n",
      "Epoch 4/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_out_RootMeanSquaredError: 0.5390 - aux_out_loss: 0.2907 - loss: 0.2913 - main_out_RootMeanSquaredError: 0.5392 - main_out_loss: 0.2913 - val_aux_out_RootMeanSquaredError: 0.4775 - val_aux_out_loss: 0.2272 - val_loss: 0.2220 - val_main_out_RootMeanSquaredError: 0.4705 - val_main_out_loss: 0.2208\n",
      "Epoch 5/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_out_RootMeanSquaredError: 0.5261 - aux_out_loss: 0.2770 - loss: 0.2753 - main_out_RootMeanSquaredError: 0.5240 - main_out_loss: 0.2751 - val_aux_out_RootMeanSquaredError: 0.4696 - val_aux_out_loss: 0.2202 - val_loss: 0.2151 - val_main_out_RootMeanSquaredError: 0.4631 - val_main_out_loss: 0.2142\n",
      "Epoch 6/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_out_RootMeanSquaredError: 0.5157 - aux_out_loss: 0.2661 - loss: 0.2634 - main_out_RootMeanSquaredError: 0.5126 - main_out_loss: 0.2631 - val_aux_out_RootMeanSquaredError: 0.4646 - val_aux_out_loss: 0.2155 - val_loss: 0.2115 - val_main_out_RootMeanSquaredError: 0.4594 - val_main_out_loss: 0.2109\n",
      "Epoch 7/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - aux_out_RootMeanSquaredError: 0.5071 - aux_out_loss: 0.2573 - loss: 0.2570 - main_out_RootMeanSquaredError: 0.5067 - main_out_loss: 0.2570 - val_aux_out_RootMeanSquaredError: 0.4600 - val_aux_out_loss: 0.2116 - val_loss: 0.2069 - val_main_out_RootMeanSquaredError: 0.4543 - val_main_out_loss: 0.2062\n",
      "Epoch 8/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - aux_out_RootMeanSquaredError: 0.4977 - aux_out_loss: 0.2478 - loss: 0.2572 - main_out_RootMeanSquaredError: 0.5080 - main_out_loss: 0.2582 - val_aux_out_RootMeanSquaredError: 0.4553 - val_aux_out_loss: 0.2074 - val_loss: 0.2062 - val_main_out_RootMeanSquaredError: 0.4540 - val_main_out_loss: 0.2060\n",
      "Epoch 9/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_out_RootMeanSquaredError: 0.4918 - aux_out_loss: 0.2420 - loss: 0.2499 - main_out_RootMeanSquaredError: 0.5006 - main_out_loss: 0.2507 - val_aux_out_RootMeanSquaredError: 0.4509 - val_aux_out_loss: 0.2033 - val_loss: 0.2009 - val_main_out_RootMeanSquaredError: 0.4480 - val_main_out_loss: 0.2007\n",
      "Epoch 10/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_out_RootMeanSquaredError: 0.4844 - aux_out_loss: 0.2347 - loss: 0.2412 - main_out_RootMeanSquaredError: 0.4918 - main_out_loss: 0.2419 - val_aux_out_RootMeanSquaredError: 0.4491 - val_aux_out_loss: 0.2018 - val_loss: 0.1999 - val_main_out_RootMeanSquaredError: 0.4468 - val_main_out_loss: 0.1998\n",
      "Epoch 11/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_out_RootMeanSquaredError: 0.4801 - aux_out_loss: 0.2306 - loss: 0.2356 - main_out_RootMeanSquaredError: 0.4859 - main_out_loss: 0.2362 - val_aux_out_RootMeanSquaredError: 0.4463 - val_aux_out_loss: 0.1992 - val_loss: 0.1975 - val_main_out_RootMeanSquaredError: 0.4443 - val_main_out_loss: 0.1974\n",
      "Epoch 12/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_out_RootMeanSquaredError: 0.4765 - aux_out_loss: 0.2271 - loss: 0.2287 - main_out_RootMeanSquaredError: 0.4783 - main_out_loss: 0.2289 - val_aux_out_RootMeanSquaredError: 0.4455 - val_aux_out_loss: 0.1984 - val_loss: 0.1961 - val_main_out_RootMeanSquaredError: 0.4425 - val_main_out_loss: 0.1960\n",
      "Epoch 13/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_out_RootMeanSquaredError: 0.4726 - aux_out_loss: 0.2235 - loss: 0.2228 - main_out_RootMeanSquaredError: 0.4718 - main_out_loss: 0.2227 - val_aux_out_RootMeanSquaredError: 0.4435 - val_aux_out_loss: 0.1968 - val_loss: 0.1948 - val_main_out_RootMeanSquaredError: 0.4411 - val_main_out_loss: 0.1947\n",
      "Epoch 14/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_out_RootMeanSquaredError: 0.4693 - aux_out_loss: 0.2204 - loss: 0.2182 - main_out_RootMeanSquaredError: 0.4668 - main_out_loss: 0.2180 - val_aux_out_RootMeanSquaredError: 0.4409 - val_aux_out_loss: 0.1945 - val_loss: 0.1932 - val_main_out_RootMeanSquaredError: 0.4393 - val_main_out_loss: 0.1933\n",
      "Epoch 15/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_out_RootMeanSquaredError: 0.4658 - aux_out_loss: 0.2171 - loss: 0.2139 - main_out_RootMeanSquaredError: 0.4620 - main_out_loss: 0.2135 - val_aux_out_RootMeanSquaredError: 0.4395 - val_aux_out_loss: 0.1930 - val_loss: 0.1910 - val_main_out_RootMeanSquaredError: 0.4368 - val_main_out_loss: 0.1907\n",
      "Epoch 16/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_out_RootMeanSquaredError: 0.4631 - aux_out_loss: 0.2146 - loss: 0.2110 - main_out_RootMeanSquaredError: 0.4589 - main_out_loss: 0.2106 - val_aux_out_RootMeanSquaredError: 0.4383 - val_aux_out_loss: 0.1920 - val_loss: 0.1905 - val_main_out_RootMeanSquaredError: 0.4363 - val_main_out_loss: 0.1905\n",
      "Epoch 17/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_out_RootMeanSquaredError: 0.4608 - aux_out_loss: 0.2124 - loss: 0.2090 - main_out_RootMeanSquaredError: 0.4567 - main_out_loss: 0.2086 - val_aux_out_RootMeanSquaredError: 0.4383 - val_aux_out_loss: 0.1918 - val_loss: 0.1897 - val_main_out_RootMeanSquaredError: 0.4353 - val_main_out_loss: 0.1894\n",
      "Epoch 18/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - aux_out_RootMeanSquaredError: 0.4591 - aux_out_loss: 0.2109 - loss: 0.2076 - main_out_RootMeanSquaredError: 0.4551 - main_out_loss: 0.2072 - val_aux_out_RootMeanSquaredError: 0.4371 - val_aux_out_loss: 0.1908 - val_loss: 0.1895 - val_main_out_RootMeanSquaredError: 0.4352 - val_main_out_loss: 0.1893\n",
      "Epoch 19/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - aux_out_RootMeanSquaredError: 0.4577 - aux_out_loss: 0.2096 - loss: 0.2064 - main_out_RootMeanSquaredError: 0.4538 - main_out_loss: 0.2060 - val_aux_out_RootMeanSquaredError: 0.4365 - val_aux_out_loss: 0.1903 - val_loss: 0.1881 - val_main_out_RootMeanSquaredError: 0.4333 - val_main_out_loss: 0.1878\n",
      "Epoch 20/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - aux_out_RootMeanSquaredError: 0.4568 - aux_out_loss: 0.2088 - loss: 0.2060 - main_out_RootMeanSquaredError: 0.4534 - main_out_loss: 0.2057 - val_aux_out_RootMeanSquaredError: 0.4367 - val_aux_out_loss: 0.1904 - val_loss: 0.1894 - val_main_out_RootMeanSquaredError: 0.4351 - val_main_out_loss: 0.1894\n",
      "Epoch 21/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - aux_out_RootMeanSquaredError: 0.4575 - aux_out_loss: 0.2094 - loss: 0.2073 - main_out_RootMeanSquaredError: 0.4550 - main_out_loss: 0.2071 - val_aux_out_RootMeanSquaredError: 0.4352 - val_aux_out_loss: 0.1891 - val_loss: 0.1872 - val_main_out_RootMeanSquaredError: 0.4324 - val_main_out_loss: 0.1867\n",
      "Epoch 22/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - aux_out_RootMeanSquaredError: 0.4533 - aux_out_loss: 0.2056 - loss: 0.2018 - main_out_RootMeanSquaredError: 0.4486 - main_out_loss: 0.2014 - val_aux_out_RootMeanSquaredError: 0.4347 - val_aux_out_loss: 0.1887 - val_loss: 0.1876 - val_main_out_RootMeanSquaredError: 0.4329 - val_main_out_loss: 0.1873\n",
      "Epoch 23/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - aux_out_RootMeanSquaredError: 0.4509 - aux_out_loss: 0.2034 - loss: 0.1993 - main_out_RootMeanSquaredError: 0.4459 - main_out_loss: 0.1989 - val_aux_out_RootMeanSquaredError: 0.4339 - val_aux_out_loss: 0.1881 - val_loss: 0.1862 - val_main_out_RootMeanSquaredError: 0.4313 - val_main_out_loss: 0.1859\n",
      "Epoch 24/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - aux_out_RootMeanSquaredError: 0.4497 - aux_out_loss: 0.2023 - loss: 0.1985 - main_out_RootMeanSquaredError: 0.4450 - main_out_loss: 0.1981 - val_aux_out_RootMeanSquaredError: 0.4342 - val_aux_out_loss: 0.1882 - val_loss: 0.1867 - val_main_out_RootMeanSquaredError: 0.4319 - val_main_out_loss: 0.1865\n",
      "Epoch 25/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - aux_out_RootMeanSquaredError: 0.4480 - aux_out_loss: 0.2008 - loss: 0.1979 - main_out_RootMeanSquaredError: 0.4444 - main_out_loss: 0.1975 - val_aux_out_RootMeanSquaredError: 0.4328 - val_aux_out_loss: 0.1871 - val_loss: 0.1854 - val_main_out_RootMeanSquaredError: 0.4304 - val_main_out_loss: 0.1852\n",
      "Epoch 26/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - aux_out_RootMeanSquaredError: 0.4475 - aux_out_loss: 0.2003 - loss: 0.1979 - main_out_RootMeanSquaredError: 0.4445 - main_out_loss: 0.1976 - val_aux_out_RootMeanSquaredError: 0.4340 - val_aux_out_loss: 0.1881 - val_loss: 0.1867 - val_main_out_RootMeanSquaredError: 0.4318 - val_main_out_loss: 0.1865\n",
      "Epoch 27/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - aux_out_RootMeanSquaredError: 0.4459 - aux_out_loss: 0.1989 - loss: 0.1970 - main_out_RootMeanSquaredError: 0.4435 - main_out_loss: 0.1968 - val_aux_out_RootMeanSquaredError: 0.4313 - val_aux_out_loss: 0.1859 - val_loss: 0.1846 - val_main_out_RootMeanSquaredError: 0.4295 - val_main_out_loss: 0.1844\n",
      "Epoch 28/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - aux_out_RootMeanSquaredError: 0.4467 - aux_out_loss: 0.1996 - loss: 0.1979 - main_out_RootMeanSquaredError: 0.4446 - main_out_loss: 0.1978 - val_aux_out_RootMeanSquaredError: 0.4343 - val_aux_out_loss: 0.1881 - val_loss: 0.1874 - val_main_out_RootMeanSquaredError: 0.4328 - val_main_out_loss: 0.1872\n",
      "Epoch 29/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - aux_out_RootMeanSquaredError: 0.4450 - aux_out_loss: 0.1981 - loss: 0.1954 - main_out_RootMeanSquaredError: 0.4416 - main_out_loss: 0.1951 - val_aux_out_RootMeanSquaredError: 0.4313 - val_aux_out_loss: 0.1859 - val_loss: 0.1847 - val_main_out_RootMeanSquaredError: 0.4295 - val_main_out_loss: 0.1844\n",
      "Epoch 30/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - aux_out_RootMeanSquaredError: 0.4426 - aux_out_loss: 0.1960 - loss: 0.1912 - main_out_RootMeanSquaredError: 0.4365 - main_out_loss: 0.1907 - val_aux_out_RootMeanSquaredError: 0.4322 - val_aux_out_loss: 0.1866 - val_loss: 0.1852 - val_main_out_RootMeanSquaredError: 0.4301 - val_main_out_loss: 0.1850\n",
      "Epoch 31/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - aux_out_RootMeanSquaredError: 0.4409 - aux_out_loss: 0.1945 - loss: 0.1894 - main_out_RootMeanSquaredError: 0.4344 - main_out_loss: 0.1888 - val_aux_out_RootMeanSquaredError: 0.4311 - val_aux_out_loss: 0.1858 - val_loss: 0.1840 - val_main_out_RootMeanSquaredError: 0.4287 - val_main_out_loss: 0.1837\n",
      "Epoch 32/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - aux_out_RootMeanSquaredError: 0.4403 - aux_out_loss: 0.1939 - loss: 0.1888 - main_out_RootMeanSquaredError: 0.4337 - main_out_loss: 0.1882 - val_aux_out_RootMeanSquaredError: 0.4328 - val_aux_out_loss: 0.1869 - val_loss: 0.1850 - val_main_out_RootMeanSquaredError: 0.4298 - val_main_out_loss: 0.1847\n",
      "Epoch 33/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - aux_out_RootMeanSquaredError: 0.4390 - aux_out_loss: 0.1928 - loss: 0.1880 - main_out_RootMeanSquaredError: 0.4329 - main_out_loss: 0.1875 - val_aux_out_RootMeanSquaredError: 0.4311 - val_aux_out_loss: 0.1856 - val_loss: 0.1837 - val_main_out_RootMeanSquaredError: 0.4284 - val_main_out_loss: 0.1834\n",
      "Epoch 34/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - aux_out_RootMeanSquaredError: 0.4392 - aux_out_loss: 0.1930 - loss: 0.1887 - main_out_RootMeanSquaredError: 0.4337 - main_out_loss: 0.1882 - val_aux_out_RootMeanSquaredError: 0.4335 - val_aux_out_loss: 0.1875 - val_loss: 0.1854 - val_main_out_RootMeanSquaredError: 0.4303 - val_main_out_loss: 0.1851\n",
      "Epoch 35/35\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - aux_out_RootMeanSquaredError: 0.4381 - aux_out_loss: 0.1920 - loss: 0.1887 - main_out_RootMeanSquaredError: 0.4338 - main_out_loss: 0.1883 - val_aux_out_RootMeanSquaredError: 0.4314 - val_aux_out_loss: 0.1860 - val_loss: 0.1841 - val_main_out_RootMeanSquaredError: 0.4288 - val_main_out_loss: 0.1838\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    (X_train_wide, X_train_deep),(y_train_scaled, y_train_scaled), epochs=35, \n",
    "    validation_data = ((X_valid_wide, X_valid_deep),(y_valid_scaled,y_valid_scaled))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e5038e",
   "metadata": {},
   "source": [
    "When we evaluate the model, Keras returns the weighted sum of the losses, as well as the individual losses and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9803995c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - dense_15_RootMeanSquaredError: 0.4410 - dense_15_loss: 0.1948 - dense_16_RootMeanSquaredError: 0.4463 - dense_16_loss: 0.1995 - loss: 0.1953\n"
     ]
    }
   ],
   "source": [
    "eval_results = model.evaluate((X_test_wide, X_test_deep),(y_test_scaled, y_test_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b649fd3e",
   "metadata": {},
   "source": [
    "The predict() method returns predictions for each output as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e0d63e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux = model.predict((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e6f17bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListWrapper(['main_out', 'aux_out'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c6b54a",
   "metadata": {},
   "source": [
    "The predict() method returns a tuple, and it does not have a return_dict argument to get a dictionary instead. However - we can create one using model.output_names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ee6a0b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_tuple = model.predict((X_new_wide, X_new_deep))\n",
    "y_pred = dict(zip(model.output_names, y_pred_tuple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2d8f5906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'main_out': array([[ 0.2391272],\n",
       "        [-1.0580845],\n",
       "        [-0.7071378]], dtype=float32),\n",
       " 'aux_out': array([[ 0.23888652],\n",
       "        [-1.1380088 ],\n",
       "        [-0.6938181 ]], dtype=float32)}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933d9cb5",
   "metadata": {},
   "source": [
    "As seen in this example - you can build all sorts of architectures with the functional api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d146a0b",
   "metadata": {},
   "source": [
    "**Using the Subclassing API to build dynamic models:**\n",
    "- both the sequential and dynamic api work but - they're static.  Some models involve loops, varying shapes, conditional branching, and other dynamic behaviour. for such cases, or if you simply prefer a more imperative programming style - the subclassing API is for you\n",
    "- With this approach - you subclass the Model class, create the layers you need in the constructor, and then use them to perform the computations you want in the call() method. For example - creating an instance of the following WideAnddeepModel class gives us an equivalent model to the one we built with the functionalapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2397da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(tf.keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.norm_layer_wide = tf.keras.layers.Normalization()\n",
    "        self.norm_layer_deep = tf.keras.layers.Normalization()\n",
    "        self.hidden1 = tf.keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = tf.keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = tf.keras.layers.Dense(1)\n",
    "        self.aux_output = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_wide, input_deep = inputs\n",
    "        norm_wide = self.norm_layer_wide(input_wide)\n",
    "        norm_deep = self.norm_layer_deep(input_deep)\n",
    "        hidden1 = self.hidden1(norm_deep)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "        output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "be552e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideAndDeepModel(30, activation=\"relu\", name=\"my_cool_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ab2d59",
   "metadata": {},
   "source": [
    "Model looks like the prev one - except - we separate the creation of the layers in the constructor from their usage in the call() method. We also don't need to create the Input objects: we can use the input argument to the call() method. \n",
    "\n",
    "Now that we have a model instance, we can compile it, adapt its normalization layers (e.g. using model.norm_layer_wide.adapt(), and model.norm_layer_deep.adapt()), and fit it, evaluate it, and use it to make predictions, exactly like we did with the functional API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8f1b03",
   "metadata": {},
   "source": [
    "**Saving and Restoring a Model:**\n",
    "- saving a trained keras model is as simple as it gets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a17c9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\blais\\Documents\\ML\\venv2\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:107: UserWarning: You are saving a model that has not yet been built. It might not contain any weights yet. Consider building the model first by calling it on some data.\n",
      "  return saving_lib.save_model(model, filepath)\n"
     ]
    }
   ],
   "source": [
    "model.save(\"../data/my_keras_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04850e3d",
   "metadata": {},
   "source": [
    "when you set the save_format = \"tf\" - keras saves the model using tensorflow's savedmodel format - a directory with the given name containing several files and subdirectories. In particular - saved_model.pb contains the model's architecture and logic in the form of a serialized graph - keras_metadata.pb file contains extra info needed by keras - the variables subdirectory contains all the parameter values (including the connection weights, the biases, the normalization statistics, and the optimizer's parameters), possibly split across multi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6840c0",
   "metadata": {},
   "source": [
    "saving just the weights is faster and uses less disk space than saving the whole model, so its perfect to save quick checkpoints during training. If you're training a big model - use checkppints regularly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12e5513",
   "metadata": {},
   "source": [
    "**Using Callbacks:**\n",
    "- the fit() method accepts a callbacks argument that lets you specify a list of objects that keras will call before and after training, before and after each epoch, and even before processing each batch. For example, the  ModelCheckpoint callback saves checkpoints of your model at regular intervals during training by default at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6c6fc3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"../data/my_checkpoints/checkpoint.weights.h5\", save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b386ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([...], callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f82712",
   "metadata": {},
   "source": [
    "If you use a validation set during training - you can set save_best_only to True - when creating the ModelCheckpoint. In this case - it will only save your model when its performance on the validation set is the best so far. This way - you don't need to worry about training for too long and overfitting the training set: simply restore the last saved model after training - this will be the best model on the validation set. \n",
    "\n",
    "\n",
    "Another way is to use the EarlyStopping callback - it will interrupt training when it measures no progress on the validation set for a number of epochs - defined by the patience argument. - if you set the restore_best_weights argument to true - it will rollback to the best model at the end of training. Can combine both callbacks to - save checkpoints of your model - in case your computer crashes - and to interrupt training early when there is no more progress to avoid wasting time and resources and to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176ba020",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae8d5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([...], callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba02485",
   "metadata": {},
   "source": [
    "Check - tf callbacks package for other callbacks. For extra control - you can easily write your pwn custom callbacks - e.g. the folliwing custom callback will display the ratio between the validation and training loss during training (e.g. to detect overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a5e1eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        ratio = logs['val_loss']/logs['loss']\n",
    "        print(f\"Epoch = {epoch}, val/train={ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515532dc",
   "metadata": {},
   "source": [
    "As you might expect, you can implement on_train_begin(), on_train_end(), on_epoch_begin(), on_epoch_end(), on_batch_begin(), and on_batch_end(). Callbacks can also be used during evaluation and predictions, should you ever need them (e.g. for debugging). For evaluation, implement on_test_begin(), on_test_end(), on_test_batch_begin(), on_test_batch_end(), which are called by evaluate(). For prediction - on_predict_begin() - on_predict_end...on_predict_batch_begin or on_predict_batch_end which are called by predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3a93be",
   "metadata": {},
   "source": [
    "**Using TensorBoard for Visualization:**\n",
    "- Tensorboard - great interactive viz tool to view learning curves during training, compare curves and metrics between multiple runs, visualize the computation graph, analyze training stats.\n",
    "- View learning curves during training, compare curves and metrics between multiple runs, viz the computation graph, analyze training statistics, view images generated by the model, visualize complex multidimensional data projected down to 3D and automatically clustered for you, profile your network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e97e091",
   "metadata": {},
   "source": [
    "Run the command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8a2b173e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U tensorboard-plugin-profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "986aecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U tensorboard-plugin-profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df7b9f0",
   "metadata": {},
   "source": [
    "To use tensorboard - modify your program so that it outputs the data you want to visualize to special binary logfiles called event files. Each binary data record is called a summary. \n",
    "Configure tensorboard to monifor the root log directory and configure the program to write to a different subdirectory every time it runs. This way, the same tensorboard server instance will allow you to visualize and compare data from multiple runs of your program, w/o getting everything mixed up.\n",
    "\n",
    "- Let's name the root log directory my_logs - and define a little fxn that generates the path of the log subdirectory based on the current date and time, so that its different at every run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "17949865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from time import strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5b9f2cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_logdir(root_logdir=\"my_logs\"):\n",
    "    return Path(root_logdir)/strftime(\"run_%Y_%m_%d_%H_%M_%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3429bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4efc40f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('my_logs/run_2025_07_20_09_32_35')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7637a00f",
   "metadata": {},
   "source": [
    "Keras provides a convenient TensorBoard() callback that will take care of creating the log directory for you (along with its parent directories if needed) - and will create eventfiles and write summaries to them during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9546a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir, profile_batch=(100,200))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
