{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d70c75ce",
   "metadata": {},
   "source": [
    "**Implementing Convolutional Layers with Keras:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "694a74cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_sample_images\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ae5daf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1ba2a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_sample_images()[\"images\"]\n",
    "images = tf.keras.layers.CenterCrop(height=70, width=120)(images)\n",
    "images = tf.keras.layers.Rescaling(scale=1/255)(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0057c539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 70, 120, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70b55f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = tf.keras.layers.Conv2D(filters=32, kernel_size=7)\n",
    "fmaps = conv_layer(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9fbee8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 64, 114, 32])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmaps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47990ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = tf.keras.layers.Conv2D(filters=32, kernel_size=7, padding=\"same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86e6fea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmaps = conv_layer(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16c9bf68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 70, 120, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmaps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be5a4d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels, biases = conv_layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08db777a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7, 3, 32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d45ed9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b3f8a3",
   "metadata": {},
   "source": [
    "**Pooling Layers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5908289",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pool = tf.keras.layers.MaxPool2D(pool_size=2)\n",
    "# strides default to the kernel size - so this layer uses a stride of 2 and by default also uses valid padding, i.e. no padding "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff8cde8",
   "metadata": {},
   "source": [
    "Max pooling - offers stronger translation invariance than avg pooling. We could also have depthwise maxpooling although its not as common. This can allow the cnn to be invariant to various features - for example it could learn multiple features each detecting a different rotation of the same pattern and the depthwise max pooling layer would ensure the output is the same regardless of the rotation. The CNN could similarly learn to be invariant to anything: thickness, brightness, skew, color, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b8eaa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom depthwise max pool layer\n",
    "\n",
    "class DepthPool(tf.keras.layers.Layer):\n",
    "    def __init__(self, pool_size=2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.pool_size = pool_size\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        shape = tf.shape(inputs) # shape[-1] is the number of channels\n",
    "        groups = shape[-1] // self.pool_size # number of channel groups\n",
    "        new_shape = tf.concat([shape[:-1],[groups, self.pool_size]], axis=0)\n",
    "        return tf.reduce_max(tf.reshape(inputs, new_shape), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82230317",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_avg_pool = tf.keras.layers.GlobalAvgPool2D()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ac10f3",
   "metadata": {},
   "source": [
    "Common mistake is to use convolution kernels that are too large. For example, instead of using a conv layer with a 5x5 kernel, stack 2 layers with 3x3 kernels: it will use fewer parameters and will require fewer computations, and will perform better. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd139dd",
   "metadata": {},
   "source": [
    "**Basic CNN to tackle the Fashion MNIST problem:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70ede14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1351b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DefaultConv2D = partial(tf.keras.layers.Conv2D, kernel_size=3, padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40fac8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=[28,28,1]),\n",
    "    DefaultConv2D(filters=64, kernel_size=7),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    DefaultConv2D(filters=256),\n",
    "    DefaultConv2D(filters=256),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=128, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(units=64, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(units=10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543f131c",
   "metadata": {},
   "source": [
    "**LeNet-5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccefb53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
